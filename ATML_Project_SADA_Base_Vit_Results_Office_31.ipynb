{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "41ugZ06WBPER",
        "k9Y3ne2WE0z1",
        "ymRBA9OTImee",
        "vrWNwJeBMfvA",
        "zHDAoBjnMDFa",
        "hFNlKjLoEcbu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "310cb098567d491ba80edc65230fd8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe8f337d68a64de8ac36415d30aace48",
              "IPY_MODEL_74602820db644b31a7bb51cb40781317",
              "IPY_MODEL_e24de75b6c23419c9170eb345c84a581"
            ],
            "layout": "IPY_MODEL_34720a310b6d4366bb888c448874ad78"
          }
        },
        "fe8f337d68a64de8ac36415d30aace48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913a5147448e4098a2fce04d725478a1",
            "placeholder": "​",
            "style": "IPY_MODEL_5880c3b17dde4712ba8cae61498a51ce",
            "value": "model.safetensors: 100%"
          }
        },
        "74602820db644b31a7bb51cb40781317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3400ac5d791a4d7881e6a42b7363e565",
            "max": 343208552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dd29d3bc53440a694befa364e8059f8",
            "value": 343208552
          }
        },
        "e24de75b6c23419c9170eb345c84a581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4604d425a264dcda73d8ee1db15759f",
            "placeholder": "​",
            "style": "IPY_MODEL_3708e28b5cae45faacc8711d54603efb",
            "value": " 343M/343M [00:08&lt;00:00, 42.8MB/s]"
          }
        },
        "34720a310b6d4366bb888c448874ad78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913a5147448e4098a2fce04d725478a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5880c3b17dde4712ba8cae61498a51ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3400ac5d791a4d7881e6a42b7363e565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd29d3bc53440a694befa364e8059f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4604d425a264dcda73d8ee1db15759f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3708e28b5cae45faacc8711d54603efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c48f6ad0ff84360ae8c891ef0c4a4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1594be77f514346bf3f721c1da5bf28",
              "IPY_MODEL_0e1f078c966a4a2ca5e41110406f48c4",
              "IPY_MODEL_88501ccc81404a3cadc67348b1234b86"
            ],
            "layout": "IPY_MODEL_b6812364bcbb4219b6ae1820079be44f"
          }
        },
        "a1594be77f514346bf3f721c1da5bf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1e6d38bbf4436d92ebbde9921f9896",
            "placeholder": "​",
            "style": "IPY_MODEL_02db596eea7d49e19c8cbf743142bd49",
            "value": "model.safetensors: 100%"
          }
        },
        "0e1f078c966a4a2ca5e41110406f48c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81eac5a926d6420c92eb45aaaf023f18",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_862b3da5d215479196b63d30d063a9d8",
            "value": 346284714
          }
        },
        "88501ccc81404a3cadc67348b1234b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ec44e7aa2c428c96dcf91b982aa37d",
            "placeholder": "​",
            "style": "IPY_MODEL_4848a9e8e94049e4849c2c3083a45b57",
            "value": " 346M/346M [00:01&lt;00:00, 233MB/s]"
          }
        },
        "b6812364bcbb4219b6ae1820079be44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1e6d38bbf4436d92ebbde9921f9896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02db596eea7d49e19c8cbf743142bd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81eac5a926d6420c92eb45aaaf023f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "862b3da5d215479196b63d30d063a9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58ec44e7aa2c428c96dcf91b982aa37d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4848a9e8e94049e4849c2c3083a45b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip installed install datasets"
      ],
      "metadata": {
        "id": "Z75mnFTp_ztC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8caf6e9-be5f-4440-d424-d6c50b06ae74",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TIbI4UQ3_rn-"
      },
      "outputs": [],
      "source": [
        "# --------------------- Imports ------------------------- #\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import vit_b_16\n",
        "\n",
        "# Datasets\n",
        "# from datasets import load_dataset\n",
        "import kagglehub\n",
        "\n",
        "# Extra\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Office-31"
      ],
      "metadata": {
        "id": "spAb68AuAgn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Office31(domain, transform):\n",
        "    path = kagglehub.dataset_download(\"xixuhu/office31\")\n",
        "    path = os.path.join(os.path.join(path, \"Office-31\"), domain)\n",
        "    return datasets.ImageFolder(root=path, transform=transform)\n",
        "\n",
        "def get_office_data_loaders(batch_size):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "\n",
        "    amazon_data = Office31(\"amazon\", transform)\n",
        "    dslr_data = Office31(\"dslr\", transform)\n",
        "    webcam_data = Office31(\"webcam\", transform)\n",
        "\n",
        "    loader_amazon = DataLoader(amazon_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_dslr = DataLoader(dslr_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_webcam = DataLoader(webcam_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader_amazon, loader_dslr, loader_webcam"
      ],
      "metadata": {
        "id": "NnwP93vyAIgb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pacs"
      ],
      "metadata": {
        "id": "QXWb4KN2AlBd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KbFM2fmAmor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Py4n_wFMBSYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Cards"
      ],
      "metadata": {
        "id": "wp0Ewd14AnBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        base_model = torchvision.models.resnet50(pretrained=pretrained)\n",
        "        self.conv1 = base_model.conv1\n",
        "        self.bn1 = base_model.bn1\n",
        "        self.relu = base_model.relu\n",
        "        self.maxpool = base_model.maxpool\n",
        "        self.layer1 = base_model.layer1\n",
        "        self.layer2 = base_model.layer2\n",
        "        self.layer3 = base_model.layer3\n",
        "        self.layer4 = base_model.layer4\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        f_block1 = self.layer1(x)\n",
        "        f_block2 = self.layer2(f_block1)\n",
        "        f_block3 = self.layer3(f_block2)\n",
        "        f_block4 = self.layer4(f_block3)\n",
        "\n",
        "        return f_block2, f_block3, f_block4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class VitBasicFeatureExtractor(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained=True, layers=[4, 8, 12]):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.model = timm.create_model('vit_base_patch16_224.sam_in1k', pretrained=pretrained, features_only=True)\n",
        "        self.model = timm.create_model('vit_base_patch16_224', pretrained=pretrained, features_only=True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        features = self.model(x)\n",
        "        pooled_features = []\n",
        "        for feature in features:\n",
        "            pooled = self.avgpool(feature)\n",
        "            pooled = pooled.view(pooled.size(0), -1)\n",
        "            pooled_features.append(pooled)\n",
        "\n",
        "        return tuple(pooled_features)\n"
      ],
      "metadata": {
        "id": "Hr4oJ4dfApKH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VitBasicFeatureExtractor(pretrained=True)\n",
        "\n",
        "input = torch.randn(16, 3, 224, 224)\n",
        "output = model(input)\n",
        "\n",
        "for out in output:\n",
        "    print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "310cb098567d491ba80edc65230fd8db",
            "fe8f337d68a64de8ac36415d30aace48",
            "74602820db644b31a7bb51cb40781317",
            "e24de75b6c23419c9170eb345c84a581",
            "34720a310b6d4366bb888c448874ad78",
            "913a5147448e4098a2fce04d725478a1",
            "5880c3b17dde4712ba8cae61498a51ce",
            "3400ac5d791a4d7881e6a42b7363e565",
            "0dd29d3bc53440a694befa364e8059f8",
            "f4604d425a264dcda73d8ee1db15759f",
            "3708e28b5cae45faacc8711d54603efb"
          ]
        },
        "id": "tLUNKNb9BWZp",
        "outputId": "99bf68b0-b8fd-4b74-fca9-9e5b755e13a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "310cb098567d491ba80edc65230fd8db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 768])\n",
            "torch.Size([16, 768])\n",
            "torch.Size([16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class SparseAutoencoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=2048, hidden_dim=1024, latent_dim=768, dropout_rate=0.3):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, latent_dim),\n",
        "            nn.LayerNorm(latent_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # Kaiming initialization for layers followed by ReLU\n",
        "                init.kaiming_uniform_(m.weight, a=0, nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                # Initialize LayerNorm with weight=1 and bias=0\n",
        "                init.ones_(m.weight)\n",
        "                init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, z\n"
      ],
      "metadata": {
        "id": "HLNY65W8AskS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, feature_extractor, num_classes=7):\n",
        "\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, f4 = self.feature_extractor(x)\n",
        "        logits = self.classifier(f4)\n",
        "        return logits, f4\n"
      ],
      "metadata": {
        "id": "Xjm7SG84A22J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionAggregator(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim=768, num_heads=4, num_layers=1):\n",
        "        super().__init__()\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=embed_dim*4,\n",
        "            dropout=0.1,\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, z_list):\n",
        "\n",
        "        z_seq = torch.stack(z_list, dim=1)\n",
        "\n",
        "        z_seq = z_seq.transpose(0, 1)\n",
        "\n",
        "        attn_out = self.transformer_encoder(z_seq)\n",
        "\n",
        "        attn_out = attn_out.transpose(0, 1)\n",
        "        attn_out = self.norm(attn_out)\n",
        "\n",
        "        # out = attn_out.reshape(attn_out.size(0), -1)  # (B, 3*embed_dim)\n",
        "        out = torch.mean(attn_out, dim=1)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "_rLwmFZIPLrv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingAggregator(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim=768, num_input=3):\n",
        "        super().__init__()\n",
        "        self.alpha = nn.Parameter(torch.ones(num_input))\n",
        "\n",
        "    def forward(self, z_list):\n",
        "        alpha = torch.sigmoid(self.alpha)\n",
        "        z_stack = torch.stack(z_list, dim=2)\n",
        "        alpha_reshaped = alpha.view(1, 1, -1)\n",
        "        z_gated = (z_stack * alpha_reshaped).sum(dim=2)\n",
        "        return z_gated"
      ],
      "metadata": {
        "id": "vPzvfhWjQi7s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnifiedModelMultiBlockSAE(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sae_dim_block2=128,\n",
        "                 sae_dim_block3=256,\n",
        "                 sae_dim_block4=256,\n",
        "                 num_classes=7):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_extractor = VitBasicFeatureExtractor(pretrained=True)\n",
        "\n",
        "        self.sae2 = SparseAutoencoder(input_dim=768, latent_dim=768)\n",
        "        self.sae3 = SparseAutoencoder(input_dim=768, latent_dim=768)\n",
        "        self.sae4 = SparseAutoencoder(input_dim=768, latent_dim=768)\n",
        "\n",
        "        # self.attention_aggregator = AttentionAggregator(embed_dim=768, num_heads=12, num_layers=3)\n",
        "        self.gating_aggregator = GatingAggregator(embed_dim=768, num_input=2)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, f4 = self.feature_extractor(x)\n",
        "\n",
        "        # x_recon2, z2 = self.sae2(f2)\n",
        "        # x_recon3, z3 = self.sae3(f3)\n",
        "        x_recon4, z4 = self.sae4(f4)\n",
        "\n",
        "\n",
        "        # attn_out = self.attention_aggregator([z2, z3, z4])\n",
        "        # attn_out = self.gating_aggregator([z2, z3, z4])\n",
        "        # attn_out = self.gating_aggregator([z4])\n",
        "\n",
        "        class_logits = self.classifier(z4)\n",
        "\n",
        "        return (class_logits,\n",
        "                (x_recon4, z4),\n",
        "                (f4))"
      ],
      "metadata": {
        "id": "U-dyfxWWA3SC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Losses"
      ],
      "metadata": {
        "id": "41ugZ06WBPER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def irm_penalty(logits, labels):\n",
        "\n",
        "    scale = torch.tensor(1.0, requires_grad=True, device=logits.device)\n",
        "    loss_erm = F.cross_entropy(scale * logits, labels)\n",
        "\n",
        "    grad = torch.autograd.grad(loss_erm, [scale], create_graph=True)[0]\n",
        "\n",
        "    penalty = torch.sum(grad**2)\n",
        "    var = 0.0\n",
        "\n",
        "    return loss_erm, penalty, var"
      ],
      "metadata": {
        "id": "1L9aXvYeBRLM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sae_loss(recons, pools, zs, lambda_sparse=[1.0, 1.0, 1.0], lambda_reconstruction=[1.0, 1.0, 1.0]):\n",
        "\n",
        "    x2_recon, x3_recon, x4_recon = recons\n",
        "    f2p, f3p, f4p = pools\n",
        "    z2, z3, z4 = zs\n",
        "\n",
        "    rec_loss2 = F.mse_loss(x2_recon, f2p)\n",
        "    rec_loss3 = F.mse_loss(x3_recon, f3p)\n",
        "    rec_loss4 = F.mse_loss(x4_recon, f4p)\n",
        "\n",
        "    lambda_r1, lambda_r2, lambda_r3 = lambda_reconstruction\n",
        "    recon_loss_total = (lambda_r1 * rec_loss2 + lambda_r2 * rec_loss3 + lambda_r3 * rec_loss4)\n",
        "\n",
        "    l1_z2 = torch.mean(torch.abs(z2))\n",
        "    l1_z3 = torch.mean(torch.abs(z3))\n",
        "    l1_z4 = torch.mean(torch.abs(z4))\n",
        "    lambda_s1, lambda_s2, lambda_s3 = lambda_sparse\n",
        "    l1_sparsity_total = (lambda_s1 * l1_z2 + lambda_s2 * l1_z3 + lambda_s3 * l1_z4)\n",
        "\n",
        "    return recon_loss_total, l1_sparsity_total\n"
      ],
      "metadata": {
        "id": "5o_c5NnbBbB1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trian and Evaluate Functions"
      ],
      "metadata": {
        "id": "HSt6tjAxBkrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "9asqo-VoExhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main_irm_multi_sae_office(model,\n",
        "                              loader_source,\n",
        "                              test_loader,\n",
        "                              num_epochs=20,\n",
        "                              lr=1e-4,\n",
        "                              lr_sae=1e-4,\n",
        "                              lambda_irm=1.0,\n",
        "                              lambda_sae_rec=1.0,\n",
        "                              lambda_sae_sparse=1e-4,\n",
        "                              lambda_sparse=[1.0, 1.0, 1.0],\n",
        "                              lambda_reconstruction=[1.0, 1.0, 1.0],\n",
        "                              lambda_irm_pair=[1.0, 1.0, 1.0],\n",
        "                              device='cuda',\n",
        "                              verbose=False):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    def sae_forward_splits(f2p, f3p, f4p):\n",
        "        x_recon2, z2 = model.sae2(f2p)\n",
        "        x_recon3, z3 = model.sae3(f3p)\n",
        "        x_recon4, z4 = model.sae4(f4p)\n",
        "        return x_recon2, z2, x_recon3, z3, x_recon4, z4\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            class_logits_s, _, _, _, _ = model(x_s)\n",
        "\n",
        "            loss_erm_s, penalty_s, var_s = irm_penalty(class_logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s)\n",
        "            irm_pen  = 0.5 * (penalty_s)\n",
        "\n",
        "\n",
        "            w1, w2, w3 = lambda_irm_pair\n",
        "            loss_irm = w1 * (irm_loss) + w2 * (lambda_irm * irm_pen) + w3 * var_s\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, (x_recon2_s, z2_s), (x_recon3_s, z3_s), (x_recon4_s, z4_s), (f2p_s, f3p_s, f4p_s) = model(x_s)\n",
        "\n",
        "            x_recon2_s, z2_s, x_recon3_s, z3_s, x_recon4_s, z4_s = sae_forward_splits(f2p_s, f3p_s, f4p_s)\n",
        "\n",
        "            lambda_s1, lambda_s2, lambda_s3 = lambda_sparse\n",
        "            lambda_r1, lambda_r2, lambda_r3 = lambda_reconstruction\n",
        "\n",
        "            rec_loss2_s = F.mse_loss(x_recon2_s, f2p_s)\n",
        "            rec_loss2   = lambda_r1 * (rec_loss2_s)\n",
        "\n",
        "            rec_loss3_s = F.mse_loss(x_recon3_s, f3p_s)\n",
        "            rec_loss3   = lambda_r2 * (rec_loss3_s)\n",
        "\n",
        "            rec_loss4_s = F.mse_loss(x_recon4_s, f4p_s)\n",
        "            rec_loss4   = lambda_r3 * (rec_loss4_s)\n",
        "\n",
        "            rec_loss_total = (rec_loss2 + rec_loss3 + rec_loss4)\n",
        "\n",
        "            l1_2_s = torch.mean(torch.abs(z2_s))\n",
        "            l1_2   = lambda_s1 * (l1_2_s)\n",
        "\n",
        "            l1_3_s = torch.mean(torch.abs(z3_s))\n",
        "            l1_3   = lambda_s2 * (l1_3_s)\n",
        "\n",
        "            l1_4_s = torch.mean(torch.abs(z4_s))\n",
        "            l1_4   = lambda_s3 * (l1_4_s)\n",
        "\n",
        "            l1_sparsity = l1_2 + l1_3 + l1_4\n",
        "\n",
        "            sae_loss = lambda_sae_rec * rec_loss_total + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 40 == 0 and verbose:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9n1I3VJsEgb_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_irm_sae_with_warmup_office(\n",
        "    batch_size=16,\n",
        "    num_warmup_epochs=5,\n",
        "    num_main_epochs=20,\n",
        "    lr=1e-4,\n",
        "    lr_sae=1e-4,\n",
        "    lambda_irm=1.0,\n",
        "    lambda_sae_rec=1.0,\n",
        "    lambda_sae_sparse=1e-4,\n",
        "    device='cuda',\n",
        "    loader=['A', 'W'],\n",
        "    model=None,\n",
        "    verbose=False,\n",
        "    lambda_sparse=[1.0, 1.0, 1.0],\n",
        "    lambda_reconstruction=[1.0, 1.0, 1.0],\n",
        "    lambda_irm_pair=[1.0, 1.0, 0.0],\n",
        "):\n",
        "\n",
        "    loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(batch_size)\n",
        "\n",
        "    source, target = loader if loader is not None else ['A', 'W']\n",
        "\n",
        "    if source == 'A':\n",
        "        loader_source = loader_amazon\n",
        "    elif source == 'W':\n",
        "        loader_source = loader_webcam\n",
        "    elif source == 'D':\n",
        "        loader_source = loader_dslr\n",
        "\n",
        "    if target == 'A':\n",
        "        loader_target = loader_amazon\n",
        "    elif target == 'W':\n",
        "        loader_target = loader_webcam\n",
        "    elif target == 'D':\n",
        "        loader_target = loader_dslr\n",
        "\n",
        "\n",
        "    if model is None:\n",
        "        model = UnifiedModelMultiBlockSAE(512, 1024, 2048, 31)\n",
        "\n",
        "    print(\"===== Main Phase (IRM + SAE) =====\")\n",
        "\n",
        "    model = train_main_irm_multi_sae_office(model,\n",
        "                                            loader_source=loader_source,\n",
        "                                            test_loader=loader_target,\n",
        "                                            num_epochs=num_main_epochs,\n",
        "                                            lr=lr,\n",
        "                                            lr_sae=lr_sae,\n",
        "                                            lambda_irm=lambda_irm,\n",
        "                                            lambda_sae_rec=lambda_sae_rec,\n",
        "                                            lambda_sae_sparse=lambda_sae_sparse,\n",
        "                                            device=device,\n",
        "                                            verbose=verbose,\n",
        "                                            lambda_sparse=lambda_sparse,\n",
        "                                            lambda_reconstruction=lambda_reconstruction,\n",
        "                                            lambda_irm_pair=lambda_irm_pair\n",
        "                                            )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fK8JO5c-Epys"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate optm"
      ],
      "metadata": {
        "id": "VXlLEUc9IJC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main_irm_multi_sae_office(\n",
        "    model,\n",
        "    loader_source,\n",
        "    test_loader,\n",
        "    num_epochs=20,\n",
        "    lr=1e-4,\n",
        "    lr_sae=1e-4,\n",
        "    lambda_irm=1.0,\n",
        "    lambda_sae_rec=1.0,\n",
        "    lambda_sae_sparse=1e-4,\n",
        "    lambda_sparse=[1.0, 1.0, 1.0],\n",
        "    lambda_reconstruction=[1.0, 1.0, 1.0],\n",
        "    lambda_irm_pair=[1.0, 1.0, 1.0],\n",
        "    device='cuda',\n",
        "    verbose=False\n",
        "):\n",
        "    import torch.optim as optim\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    def sae_forward_splits(f4p):\n",
        "        # x_recon2, z2 = model.sae2(f2p)\n",
        "        # x_recon3, z3 = model.sae3(f3p)\n",
        "        x_recon4, z4 = model.sae4(f4p)\n",
        "        return x_recon4, z4\n",
        "\n",
        "    # Define separate optimizers\n",
        "    # Optimizer for the feature extractor and classifier\n",
        "    params_rest = [\n",
        "        p for n, p in model.named_parameters()\n",
        "        if not (n.startswith('sae2') or n.startswith('sae3') or n.startswith('sae4'))\n",
        "    ]\n",
        "    # optimizer_rest = optim.SGD(params_rest, lr=lr, momentum=0.9)\n",
        "    optimizer_rest = optim.Adam(params_rest, lr=lr)\n",
        "    # Optimizer for the Sparse Autoencoders (sae2, sae3, sae4)\n",
        "    params_sae = list(model.sae2.parameters()) + list(model.sae3.parameters()) + list(model.sae4.parameters())\n",
        "    optimizer_sae = optim.Adam(params_sae, lr=lr_sae)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            # Forward pass for classification\n",
        "            class_logits_s, _, _ = model(x_s)\n",
        "\n",
        "            # Compute IRM loss\n",
        "            loss_erm_s, penalty_s, var_s = irm_penalty(class_logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * loss_erm_s\n",
        "            irm_pen  = 0.5 * penalty_s\n",
        "\n",
        "            w1, w2, w3 = lambda_irm_pair\n",
        "            loss_irm = w1 * irm_loss + w2 * (lambda_irm * irm_pen) + w3 * var_s\n",
        "\n",
        "            # Forward pass for SAEs without tracking gradients\n",
        "            with torch.no_grad():\n",
        "                class_logits_s, (x_recon4_s, z4_s), (f4p_s) = model(x_s)\n",
        "\n",
        "            # Forward pass through SAEs to get reconstructions and latent vectors\n",
        "            x_recon4_s, z4_s = sae_forward_splits(f4p_s)\n",
        "\n",
        "            # Compute Reconstruction Loss\n",
        "            lambda_s1, lambda_s2, lambda_s3 = lambda_sparse\n",
        "            lambda_r1, lambda_r2, lambda_r3 = lambda_reconstruction\n",
        "\n",
        "\n",
        "            rec_loss4_s = F.mse_loss(x_recon4_s, f4p_s)\n",
        "            rec_loss4   = lambda_r3 * rec_loss4_s\n",
        "\n",
        "            rec_loss_total = rec_loss4\n",
        "\n",
        "            l1_4_s = torch.mean(torch.abs(z4_s))\n",
        "            l1_4   = lambda_s3 * l1_4_s\n",
        "\n",
        "            l1_sparsity = l1_4\n",
        "\n",
        "            # Total SAE Loss\n",
        "            sae_loss = lambda_sae_rec * rec_loss_total + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "\n",
        "            # Zero gradients for both optimizers\n",
        "            optimizer_rest.zero_grad()\n",
        "            optimizer_sae.zero_grad()\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer_rest.step()\n",
        "            optimizer_sae.step()\n",
        "\n",
        "            if (step+1) % 40 == 0 and verbose:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        # Evaluation after each epoch\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rYRTCpINIVwR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "k9Y3ne2WE0z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    model.train()\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "I1JnoZwcEqPk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "9ZVa9RfWEs12"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "5Efg0fiMHjya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_baseline = ResNetFeatureExtractor(pretrained=True)\n",
        "baseline_model = BaselineModel(feature_extractor=feature_extractor_baseline, num_classes=31)"
      ],
      "metadata": {
        "id": "Qp2dr4NFIwu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3320c2b5-592e-45a3-bdf6-48f534a6244e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 201MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(32)"
      ],
      "metadata": {
        "id": "_JeZUuvRJsqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a44303f-119b-4867-8768-f8af61d7fe48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xixuhu/office31?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75.9M/75.9M [00:04<00:00, 16.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline models"
      ],
      "metadata": {
        "id": "ymRBA9OTImee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A -> W"
      ],
      "metadata": {
        "id": "CTzsP6NZKZxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_amazon,\n",
        "                         loader_webcam,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "srKMMW47IjrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "fd3aa949-deb4-4840-fe61-69845aff49af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (458752x7 and 768x31)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2452e660a7ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m baseline_model = train_baseline_model_office(baseline_model,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mloader_amazon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mloader_webcam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-37369bf9ca9a>\u001b[0m in \u001b[0;36mtrain_baseline_model_office\u001b[0;34m(model, loader_source, target_loader, num_epochs, lr, lambda_irm, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mlogits_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-35a38a0d6e5b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (458752x7 and 768x31)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A -> D"
      ],
      "metadata": {
        "id": "jPAtvyACKXkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_amazon,\n",
        "                         loader_dslr,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "T_ulkoK6JyBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### W -> A"
      ],
      "metadata": {
        "id": "zws7xJ33KVe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_webcam,\n",
        "                         loader_amazon,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "7DGytvoSJzKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### W -> D"
      ],
      "metadata": {
        "id": "0CbTmzFXKSN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_webcam,\n",
        "                         loader_dslr,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "-InAQbMXKAhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D -> W"
      ],
      "metadata": {
        "id": "JoF8qXCbKPd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_dslr,\n",
        "                         loader_webcam,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "bjWJ5JvEKDfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D -> A"
      ],
      "metadata": {
        "id": "2XBdweCGKJyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_dslr,\n",
        "                         loader_amazon,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "M65hwh2CKEzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ours"
      ],
      "metadata": {
        "id": "wyB1rTLlItrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"D\"], [\"W\", \"A\"], [\"W\", \"D\"], [\"D\", \"W\"], [\"D\", \"A\"]] # Removed [\"A\", \"D\"]"
      ],
      "metadata": {
        "id": "zTV3OWYxL0ZX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A -> D **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "vrWNwJeBMfvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"A\", \"D\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            # model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=6,\n",
        "            lr=1e-6,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "ht88PjKfIuxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d579be39-8591-49c6-ca6c-a42045991eb9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "Epoch [1/6], Step [40/89], IRM Loss: 7.7358, SAE Loss: 5.7715\n",
            "Epoch [1/6], Step [80/89], IRM Loss: 5.2013, SAE Loss: 6.7702\n",
            "** End of Epoch 1/6 | Test Accuracy: 89.43% **\n",
            "Epoch [2/6], Step [40/89], IRM Loss: 0.0913, SAE Loss: 5.4998\n",
            "Epoch [2/6], Step [80/89], IRM Loss: 0.3113, SAE Loss: 5.2867\n",
            "** End of Epoch 2/6 | Test Accuracy: 91.07% **\n",
            "Epoch [3/6], Step [40/89], IRM Loss: 0.0932, SAE Loss: 6.8329\n",
            "Epoch [3/6], Step [80/89], IRM Loss: 0.1265, SAE Loss: 6.0455\n",
            "** End of Epoch 3/6 | Test Accuracy: 91.45% **\n",
            "Epoch [4/6], Step [40/89], IRM Loss: 0.0782, SAE Loss: 5.5913\n",
            "Epoch [4/6], Step [80/89], IRM Loss: 0.0847, SAE Loss: 5.7738\n",
            "** End of Epoch 4/6 | Test Accuracy: 91.07% **\n",
            "Epoch [5/6], Step [40/89], IRM Loss: 0.0900, SAE Loss: 5.3271\n",
            "Epoch [5/6], Step [80/89], IRM Loss: 0.0715, SAE Loss: 6.0006\n",
            "** End of Epoch 5/6 | Test Accuracy: 90.69% **\n",
            "Epoch [6/6], Step [40/89], IRM Loss: 0.0639, SAE Loss: 6.4612\n",
            "Epoch [6/6], Step [80/89], IRM Loss: 0.0682, SAE Loss: 5.8683\n",
            "** End of Epoch 6/6 | Test Accuracy: 90.69% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A -> W **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "zHDAoBjnMDFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            # model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=6,\n",
        "            lr=1e-5,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "2c48f6ad0ff84360ae8c891ef0c4a4d6",
            "a1594be77f514346bf3f721c1da5bf28",
            "0e1f078c966a4a2ca5e41110406f48c4",
            "88501ccc81404a3cadc67348b1234b86",
            "b6812364bcbb4219b6ae1820079be44f",
            "0e1e6d38bbf4436d92ebbde9921f9896",
            "02db596eea7d49e19c8cbf743142bd49",
            "81eac5a926d6420c92eb45aaaf023f18",
            "862b3da5d215479196b63d30d063a9d8",
            "58ec44e7aa2c428c96dcf91b982aa37d",
            "4848a9e8e94049e4849c2c3083a45b57"
          ]
        },
        "id": "vid9GyzYXnJX",
        "outputId": "64185120-36b2-4ef0-db1f-b975581529fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c48f6ad0ff84360ae8c891ef0c4a4d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Main Phase (IRM + SAE) =====\n",
            "Epoch [1/6], Step [40/89], IRM Loss: 14.9789, SAE Loss: 5.4896\n",
            "Epoch [1/6], Step [80/89], IRM Loss: 13.1903, SAE Loss: 4.1527\n",
            "** End of Epoch 1/6 | Test Accuracy: 74.90% **\n",
            "Epoch [2/6], Step [40/89], IRM Loss: 2.5375, SAE Loss: 7.0794\n",
            "Epoch [2/6], Step [80/89], IRM Loss: 1.5245, SAE Loss: 7.0305\n",
            "** End of Epoch 2/6 | Test Accuracy: 88.76% **\n",
            "Epoch [3/6], Step [40/89], IRM Loss: 1.2606, SAE Loss: 6.8434\n",
            "Epoch [3/6], Step [80/89], IRM Loss: 0.7653, SAE Loss: 5.3209\n",
            "** End of Epoch 3/6 | Test Accuracy: 91.77% **\n",
            "Epoch [4/6], Step [40/89], IRM Loss: 0.4677, SAE Loss: 5.4863\n",
            "Epoch [4/6], Step [80/89], IRM Loss: 0.5548, SAE Loss: 6.4527\n",
            "** End of Epoch 4/6 | Test Accuracy: 91.57% **\n",
            "Epoch [5/6], Step [40/89], IRM Loss: 0.1260, SAE Loss: 5.8335\n",
            "Epoch [5/6], Step [80/89], IRM Loss: 0.1268, SAE Loss: 6.7935\n",
            "** End of Epoch 5/6 | Test Accuracy: 93.37% **\n",
            "Epoch [6/6], Step [40/89], IRM Loss: 0.1516, SAE Loss: 5.5576\n",
            "Epoch [6/6], Step [80/89], IRM Loss: 0.1460, SAE Loss: 6.4418\n",
            "** End of Epoch 6/6 | Test Accuracy: 92.37% **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##W -> A **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "hi3LQBlkMlXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"W\", \"A\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=1e-6,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2D7BGS-JocU",
        "outputId": "656afed4-c3a8-45e6-becf-15e286fb87ac"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 72.31% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 72.99% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 74.94% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 75.54% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 75.90% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 76.36% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 76.46% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 76.64% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 76.75% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 76.93% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 76.93% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 77.00% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 77.03% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 77.07% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 77.14% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 77.14% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 77.14% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 77.25% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 77.32% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 77.42% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 77.42% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 77.49% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 77.42% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 77.49% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 77.60% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 77.60% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 77.74% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 77.78% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 77.85% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 77.81% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## W -> D **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "nYRNGI5MMwmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"W\", \"D\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=15,\n",
        "            lr=1e-6,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptu2Pf0hMStI",
        "outputId": "4407199b-4a85-4b17-e5fe-1128c0a4e655"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['W', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/15 | Test Accuracy: 97.23% **\n",
            "** End of Epoch 2/15 | Test Accuracy: 97.23% **\n",
            "** End of Epoch 3/15 | Test Accuracy: 97.99% **\n",
            "** End of Epoch 4/15 | Test Accuracy: 98.24% **\n",
            "** End of Epoch 5/15 | Test Accuracy: 98.36% **\n",
            "** End of Epoch 6/15 | Test Accuracy: 98.49% **\n",
            "** End of Epoch 7/15 | Test Accuracy: 98.62% **\n",
            "** End of Epoch 8/15 | Test Accuracy: 98.62% **\n",
            "** End of Epoch 9/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 10/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 11/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 12/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 13/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 14/15 | Test Accuracy: 98.87% **\n",
            "** End of Epoch 15/15 | Test Accuracy: 98.87% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D -> W **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "DP1jYfNVQ_iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"D\", \"W\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            # model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=20,\n",
        "            lr=1e-5,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Y4FC9dQ_P-",
        "outputId": "b50f44a0-a0b0-4b7d-8f4f-bda3c4314ed4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['D', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/20 | Test Accuracy: 41.37% **\n",
            "** End of Epoch 2/20 | Test Accuracy: 54.82% **\n",
            "** End of Epoch 3/20 | Test Accuracy: 49.60% **\n",
            "** End of Epoch 4/20 | Test Accuracy: 74.90% **\n",
            "** End of Epoch 5/20 | Test Accuracy: 96.18% **\n",
            "** End of Epoch 6/20 | Test Accuracy: 99.80% **\n",
            "** End of Epoch 7/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 8/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 9/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 10/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 11/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 12/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 13/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 14/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 15/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 16/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 17/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 18/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 19/20 | Test Accuracy: 100.00% **\n",
            "** End of Epoch 20/20 | Test Accuracy: 100.00% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D -> A **DO** **NOT** **RUN**"
      ],
      "metadata": {
        "id": "viwb-kgBRJ_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"D\", \"A\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=20,\n",
        "            lr=1e-6,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzx4ihVERK8D",
        "outputId": "3133ac75-f844-41a9-84b5-97f6b19b93bf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/20 | Test Accuracy: 21.05% **\n",
            "** End of Epoch 2/20 | Test Accuracy: 28.51% **\n",
            "** End of Epoch 3/20 | Test Accuracy: 26.09% **\n",
            "** End of Epoch 4/20 | Test Accuracy: 47.07% **\n",
            "** End of Epoch 5/20 | Test Accuracy: 69.29% **\n",
            "** End of Epoch 6/20 | Test Accuracy: 75.33% **\n",
            "** End of Epoch 7/20 | Test Accuracy: 75.33% **\n",
            "** End of Epoch 8/20 | Test Accuracy: 75.75% **\n",
            "** End of Epoch 9/20 | Test Accuracy: 75.51% **\n",
            "** End of Epoch 10/20 | Test Accuracy: 75.36% **\n",
            "** End of Epoch 11/20 | Test Accuracy: 75.26% **\n",
            "** End of Epoch 12/20 | Test Accuracy: 75.36% **\n",
            "** End of Epoch 13/20 | Test Accuracy: 75.19% **\n",
            "** End of Epoch 14/20 | Test Accuracy: 75.08% **\n",
            "** End of Epoch 15/20 | Test Accuracy: 75.22% **\n",
            "** End of Epoch 16/20 | Test Accuracy: 75.36% **\n",
            "** End of Epoch 17/20 | Test Accuracy: 75.29% **\n",
            "** End of Epoch 18/20 | Test Accuracy: 75.26% **\n",
            "** End of Epoch 19/20 | Test Accuracy: 75.19% **\n",
            "** End of Epoch 20/20 | Test Accuracy: 75.15% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combination = [\"D\", \"A\"]\n",
        "print(f\"------------Combination: {combination}--------------\")\n",
        "lambda_irm_pair = [10.0, 4.0, 0.0]\n",
        "lambda_sparse=[0.1, 0.1, 0.1]\n",
        "\n",
        "trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            # model=trained_model_sae_office,\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=65e-7,\n",
        "            lr_sae=5e-5,\n",
        "            lambda_irm=1.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            verbose=True,\n",
        "            lambda_irm_pair=lambda_irm_pair,\n",
        "            lambda_sparse=lambda_sparse,\n",
        "            loader=combination\n",
        "        )\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "UsEksNgEaTav",
        "outputId": "33a70650-b51c-4532-c94c-5f14c8f4d96b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 28.93% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 32.34% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 29.36% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 48.21% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 65.14% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 72.95% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 73.91% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 73.80% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 74.01% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 73.91% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 74.01% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 74.09% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 74.19% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 74.16% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 74.12% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 74.16% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 74.16% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 74.09% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 74.16% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 74.26% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 74.23% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 74.26% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 74.26% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 74.30% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 74.33% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 74.37% **\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ca0f06f0b31d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlambda_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;31m# model=trained_model_sae_office,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c66ed9f3c9ab>\u001b[0m in \u001b[0;36mtrain_model_irm_sae_with_warmup_office\u001b[0;34m(batch_size, num_warmup_epochs, num_main_epochs, lr, lr_sae, lambda_irm, lambda_sae_rec, lambda_sae_sparse, device, loader, model, verbose, lambda_sparse, lambda_reconstruction, lambda_irm_pair)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Main Phase (IRM + SAE) =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     model = train_main_irm_multi_sae_office(model,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                             \u001b[0mloader_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                             \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-5da861576543>\u001b[0m in \u001b[0;36mtrain_main_irm_multi_sae_office\u001b[0;34m(model, loader_source, test_loader, num_epochs, lr, lr_sae, lambda_irm, lambda_sae_rec, lambda_sae_sparse, lambda_sparse, lambda_reconstruction, lambda_irm_pair, device, verbose)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0msource_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 )\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Vit accuracies"
      ],
      "metadata": {
        "id": "hFNlKjLoEcbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vit_b_16\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def get_base_accuracy(loader=None):\n",
        "\n",
        "    # print(f\"------------Combination: {loader}--------------\")\n",
        "\n",
        "    loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(32)\n",
        "\n",
        "    source, target = loader if loader is not None else ['A', 'W']\n",
        "\n",
        "    if source == 'A':\n",
        "        loader_source = loader_amazon\n",
        "    elif source == 'W':\n",
        "        loader_source = loader_webcam\n",
        "    elif source == 'D':\n",
        "        loader_source = loader_dslr\n",
        "\n",
        "    if target == 'A':\n",
        "        loader_target = loader_amazon\n",
        "    elif target == 'W':\n",
        "        loader_target = loader_webcam\n",
        "    elif target == 'D':\n",
        "        loader_target = loader_dslr\n",
        "\n",
        "\n",
        "    model = vit_b_16(weights=\"DEFAULT\")\n",
        "    model.heads.head = nn.Linear(in_features=768, out_features=31, bias=True)\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    optm = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    epochs = 10\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for x, y in (loader_source):\n",
        "            x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
        "\n",
        "            optm.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optm.step()\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss.item()}\")\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in (loader_target):\n",
        "                x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
        "\n",
        "                logits = model(x)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "        acc = 100.0 * correct / total\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} | Test Accuracy: {acc}\")\n",
        "\n",
        "        # print(\"--------------------------------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YgJ7rEvZq0Ea"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"W\"], [\"A\", \"D\"], [\"W\", \"A\"], [\"W\", \"D\"], [\"D\", \"W\"], [\"D\", \"A\"]]\n",
        "\n",
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    get_base_accuracy(loader=combination)\n",
        "    print(\"--------------------------------------------\")"
      ],
      "metadata": {
        "id": "8Gq9SGgzt-R6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98aff6fc-6d8b-49a1-fe9f-5bc05ed1eb49"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:01<00:00, 220MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10 | Loss: 1.2360752820968628\n",
            "Epoch: 1/10 | Test Accuracy: 62.65060240963855\n",
            "Epoch: 2/10 | Loss: 0.10394764691591263\n",
            "Epoch: 2/10 | Test Accuracy: 72.89156626506023\n",
            "Epoch: 3/10 | Loss: 0.38924047350883484\n",
            "Epoch: 3/10 | Test Accuracy: 75.90361445783132\n",
            "Epoch: 4/10 | Loss: 0.12596368789672852\n",
            "Epoch: 4/10 | Test Accuracy: 77.10843373493977\n",
            "Epoch: 5/10 | Loss: 0.5225404500961304\n",
            "Epoch: 5/10 | Test Accuracy: 77.71084337349397\n",
            "Epoch: 6/10 | Loss: 0.04771722853183746\n",
            "Epoch: 6/10 | Test Accuracy: 76.70682730923694\n",
            "Epoch: 7/10 | Loss: 0.050937213003635406\n",
            "Epoch: 7/10 | Test Accuracy: 77.51004016064257\n",
            "Epoch: 8/10 | Loss: 0.04414904862642288\n",
            "Epoch: 8/10 | Test Accuracy: 77.71084337349397\n",
            "Epoch: 9/10 | Loss: 0.014110557734966278\n",
            "Epoch: 9/10 | Test Accuracy: 79.31726907630522\n",
            "Epoch: 10/10 | Loss: 0.01729162223637104\n",
            "Epoch: 10/10 | Test Accuracy: 78.3132530120482\n",
            "--------------------------------------------\n",
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Epoch: 1/10 | Loss: 2.1436262130737305\n",
            "Epoch: 1/10 | Test Accuracy: 64.0251572327044\n",
            "Epoch: 2/10 | Loss: 0.20316632091999054\n",
            "Epoch: 2/10 | Test Accuracy: 71.06918238993711\n",
            "Epoch: 3/10 | Loss: 0.1448451280593872\n",
            "Epoch: 3/10 | Test Accuracy: 75.72327044025157\n",
            "Epoch: 4/10 | Loss: 0.6898751258850098\n",
            "Epoch: 4/10 | Test Accuracy: 78.23899371069183\n",
            "Epoch: 5/10 | Loss: 0.0342828705906868\n",
            "Epoch: 5/10 | Test Accuracy: 77.23270440251572\n",
            "Epoch: 6/10 | Loss: 0.2781428098678589\n",
            "Epoch: 6/10 | Test Accuracy: 79.11949685534591\n",
            "Epoch: 7/10 | Loss: 0.08363215625286102\n",
            "Epoch: 7/10 | Test Accuracy: 78.86792452830188\n",
            "Epoch: 8/10 | Loss: 0.019776662811636925\n",
            "Epoch: 8/10 | Test Accuracy: 77.10691823899371\n",
            "Epoch: 9/10 | Loss: 0.016802219673991203\n",
            "Epoch: 9/10 | Test Accuracy: 76.72955974842768\n",
            "Epoch: 10/10 | Loss: 0.013961272314190865\n",
            "Epoch: 10/10 | Test Accuracy: 77.10691823899371\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Epoch: 1/10 | Loss: 2.952446699142456\n",
            "Epoch: 1/10 | Test Accuracy: 9.123180688675896\n",
            "Epoch: 2/10 | Loss: 2.2513322830200195\n",
            "Epoch: 2/10 | Test Accuracy: 18.636847710330137\n",
            "Epoch: 3/10 | Loss: 1.6107970476150513\n",
            "Epoch: 3/10 | Test Accuracy: 30.95491657791977\n",
            "Epoch: 4/10 | Loss: 1.128598690032959\n",
            "Epoch: 4/10 | Test Accuracy: 40.18459353922613\n",
            "Epoch: 5/10 | Loss: 0.6663172245025635\n",
            "Epoch: 5/10 | Test Accuracy: 46.68086616968406\n",
            "Epoch: 6/10 | Loss: 0.44825321435928345\n",
            "Epoch: 6/10 | Test Accuracy: 49.27227547035854\n",
            "Epoch: 7/10 | Loss: 0.34487923979759216\n",
            "Epoch: 7/10 | Test Accuracy: 51.473198438054666\n",
            "Epoch: 8/10 | Loss: 0.3272651731967926\n",
            "Epoch: 8/10 | Test Accuracy: 52.325168619098335\n",
            "Epoch: 9/10 | Loss: 0.18158236145973206\n",
            "Epoch: 9/10 | Test Accuracy: 52.89314873979411\n",
            "Epoch: 10/10 | Loss: 0.13995379209518433\n",
            "Epoch: 10/10 | Test Accuracy: 52.89314873979411\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Epoch: 1/10 | Loss: 2.9679031372070312\n",
            "Epoch: 1/10 | Test Accuracy: 20.12578616352201\n",
            "Epoch: 2/10 | Loss: 2.1271746158599854\n",
            "Epoch: 2/10 | Test Accuracy: 41.509433962264154\n",
            "Epoch: 3/10 | Loss: 1.8731977939605713\n",
            "Epoch: 3/10 | Test Accuracy: 66.28930817610063\n",
            "Epoch: 4/10 | Loss: 1.0524486303329468\n",
            "Epoch: 4/10 | Test Accuracy: 85.03144654088051\n",
            "Epoch: 5/10 | Loss: 0.6190167665481567\n",
            "Epoch: 5/10 | Test Accuracy: 90.94339622641509\n",
            "Epoch: 6/10 | Loss: 0.5044434666633606\n",
            "Epoch: 6/10 | Test Accuracy: 94.21383647798743\n",
            "Epoch: 7/10 | Loss: 0.2722260355949402\n",
            "Epoch: 7/10 | Test Accuracy: 95.34591194968553\n",
            "Epoch: 8/10 | Loss: 0.3069843053817749\n",
            "Epoch: 8/10 | Test Accuracy: 95.84905660377359\n",
            "Epoch: 9/10 | Loss: 0.19425350427627563\n",
            "Epoch: 9/10 | Test Accuracy: 96.47798742138365\n",
            "Epoch: 10/10 | Loss: 0.1537826806306839\n",
            "Epoch: 10/10 | Test Accuracy: 96.60377358490567\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Epoch: 1/10 | Loss: 2.6728358268737793\n",
            "Epoch: 1/10 | Test Accuracy: 38.55421686746988\n",
            "Epoch: 2/10 | Loss: 1.7617594003677368\n",
            "Epoch: 2/10 | Test Accuracy: 78.11244979919678\n",
            "Epoch: 3/10 | Loss: 1.1817654371261597\n",
            "Epoch: 3/10 | Test Accuracy: 90.96385542168674\n",
            "Epoch: 4/10 | Loss: 0.6141323447227478\n",
            "Epoch: 4/10 | Test Accuracy: 94.97991967871486\n",
            "Epoch: 5/10 | Loss: 0.4434393644332886\n",
            "Epoch: 5/10 | Test Accuracy: 97.18875502008032\n",
            "Epoch: 6/10 | Loss: 0.22112371027469635\n",
            "Epoch: 6/10 | Test Accuracy: 97.99196787148594\n",
            "Epoch: 7/10 | Loss: 0.13857108354568481\n",
            "Epoch: 7/10 | Test Accuracy: 98.79518072289157\n",
            "Epoch: 8/10 | Loss: 0.1450006663799286\n",
            "Epoch: 8/10 | Test Accuracy: 98.39357429718875\n",
            "Epoch: 9/10 | Loss: 0.11386846005916595\n",
            "Epoch: 9/10 | Test Accuracy: 98.39357429718875\n",
            "Epoch: 10/10 | Loss: 0.05635327845811844\n",
            "Epoch: 10/10 | Test Accuracy: 98.39357429718875\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Epoch: 1/10 | Loss: 2.740837335586548\n",
            "Epoch: 1/10 | Test Accuracy: 13.560525381611644\n",
            "Epoch: 2/10 | Loss: 1.7874512672424316\n",
            "Epoch: 2/10 | Test Accuracy: 32.48136315228967\n",
            "Epoch: 3/10 | Loss: 1.1304984092712402\n",
            "Epoch: 3/10 | Test Accuracy: 41.99503017394391\n",
            "Epoch: 4/10 | Loss: 0.620085597038269\n",
            "Epoch: 4/10 | Test Accuracy: 47.07135250266241\n",
            "Epoch: 5/10 | Loss: 0.2930618226528168\n",
            "Epoch: 5/10 | Test Accuracy: 50.47923322683706\n",
            "Epoch: 6/10 | Loss: 0.18871240317821503\n",
            "Epoch: 6/10 | Test Accuracy: 52.325168619098335\n",
            "Epoch: 7/10 | Loss: 0.14470085501670837\n",
            "Epoch: 7/10 | Test Accuracy: 52.715654952076676\n",
            "Epoch: 8/10 | Loss: 0.0979757159948349\n",
            "Epoch: 8/10 | Test Accuracy: 53.85161519346823\n",
            "Epoch: 9/10 | Loss: 0.09273456782102585\n",
            "Epoch: 9/10 | Test Accuracy: 54.242101526446575\n",
            "Epoch: 10/10 | Loss: 0.06899580359458923\n",
            "Epoch: 10/10 | Test Accuracy: 54.27760028399006\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNrCflJldy4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}