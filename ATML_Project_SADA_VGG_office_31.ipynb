{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Notebook"
      ],
      "metadata": {
        "id": "0J65oPy2rDov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Z75mnFTp_ztC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "18c51e94-f0f4-431d-d730-d57d50b091d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIbI4UQ3_rn-"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Datasets\n",
        "from datasets import load_dataset\n",
        "import kagglehub\n",
        "\n",
        "# Extra\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Office-31"
      ],
      "metadata": {
        "id": "spAb68AuAgn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Office31(domain, transform):\n",
        "    path = kagglehub.dataset_download(\"xixuhu/office31\")\n",
        "    path = os.path.join(os.path.join(path, \"Office-31\"), domain)\n",
        "    return datasets.ImageFolder(root=path, transform=transform)\n",
        "\n",
        "def get_office_data_loaders(batch_size):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    amazon_data = Office31(\"amazon\", transform)\n",
        "    dslr_data = Office31(\"dslr\", transform)\n",
        "    webcam_data = Office31(\"webcam\", transform)\n",
        "\n",
        "    loader_amazon = DataLoader(amazon_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_dslr = DataLoader(dslr_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_webcam = DataLoader(webcam_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader_amazon, loader_dslr, loader_webcam"
      ],
      "metadata": {
        "id": "NnwP93vyAIgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_amazon, loader_dslr, loader_webcam = get_office_data_loaders(batch_size=32)"
      ],
      "metadata": {
        "id": "R8lCJWalAiyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73f651b-8b18-493b-bff8-54e22b3c331d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xixuhu/office31?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75.9M/75.9M [00:05<00:00, 15.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Cards"
      ],
      "metadata": {
        "id": "wp0Ewd14AnBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title VGG backbone\n",
        "class VGGFeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained=True, model_name='vgg16'):\n",
        "        super(VGGFeatureExtractor, self).__init__()\n",
        "\n",
        "        # Load Weights\n",
        "        if model_name == 'vgg16':\n",
        "            base_model = torchvision.models.vgg16(pretrained=pretrained)\n",
        "        elif model_name == 'vgg19':\n",
        "            base_model = torchvision.models.vgg19(pretrained=pretrained)\n",
        "\n",
        "        self.features = base_model.features\n",
        "\n",
        "        # Block 1: 0-4\n",
        "        # Block 2: 5-9\n",
        "        # Block 3: 10-16\n",
        "        # Block 4: 17-23\n",
        "        # Block 5: 24-30\n",
        "\n",
        "        # Define the layers where you want to extract features\n",
        "        self.layer_names = {\n",
        "            'block1': 4,\n",
        "            'block2': 9,\n",
        "            'block3': 16,\n",
        "            'block4': 23,\n",
        "            'block5': 30\n",
        "        }\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = {}\n",
        "\n",
        "        # Straight Forward Pass\n",
        "        # for name, layer_idx in self.layer_names.items():\n",
        "        #     # Pass the input through layers up to the current layer\n",
        "        #     for i, layer in enumerate(self.features[:layer_idx + 1]):\n",
        "        #         x = layer(x)\n",
        "        #     outputs[name] = x\n",
        "\n",
        "        # Optimised Pass\n",
        "        for i, layer in enumerate(self.features):\n",
        "          x = layer(x)\n",
        "          if i == self.layer_names['block3']:\n",
        "              outputs['block3'] = x\n",
        "          elif i == self.layer_names['block4']:\n",
        "              outputs['block4'] = x\n",
        "          elif i == self.layer_names['block5']:\n",
        "              outputs['block5'] = x\n",
        "              break  # Stop after the last required block\n",
        "\n",
        "        # Return Outputs of certain blocks\n",
        "        return outputs['block3'], outputs['block4'], outputs['block5']"
      ],
      "metadata": {
        "id": "tQNATujKAsFx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SparseAutoencoder\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, z"
      ],
      "metadata": {
        "id": "HLNY65W8AskS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ClassifierHead\n",
        "class ClassifierHead(nn.Module):\n",
        "    def __init__(self, input_dim=2048, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "HA2XtH6zAuX3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Baseline\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, feature_extractor, num_classes=7):\n",
        "\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, f4 = self.feature_extractor(x)\n",
        "        f4_pool = self.avgpool(f4).view(f4.size(0), -1)\n",
        "\n",
        "        logits = self.classifier(f4_pool)\n",
        "        return logits, f4_pool\n"
      ],
      "metadata": {
        "id": "Xjm7SG84A22J",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UnifiedModelMultiBlockSAE\n",
        "class UnifiedModelMultiBlockSAE(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sae_dim_block2=128,\n",
        "                 sae_dim_block3=256,\n",
        "                 sae_dim_block4=256,\n",
        "                 num_classes=7):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Define Feature Extractor\n",
        "\n",
        "        # self.feature_extractor = ResNetFeatureExtractor(pretrained=True)\n",
        "        # self.feature_extractor = VGGFeatureExtractor(pretrained=True)\n",
        "        self.feature_extractor = VGGFeatureExtractor(pretrained=True, model_name='vgg19')\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.sae2 = SparseAutoencoder(input_dim=256, hidden_dim=sae_dim_block2)\n",
        "        self.sae3 = SparseAutoencoder(input_dim=512, hidden_dim=sae_dim_block3)\n",
        "        self.sae4 = SparseAutoencoder(input_dim=512, hidden_dim=sae_dim_block4)\n",
        "\n",
        "        total_hidden = sae_dim_block2 + sae_dim_block3 + sae_dim_block4\n",
        "        self.classifier = nn.Linear(total_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        f2, f3, f4 = self.feature_extractor(x)\n",
        "\n",
        "        f2_pool = self.avgpool(f2).view(f2.size(0), -1)\n",
        "        f3_pool = self.avgpool(f3).view(f3.size(0), -1)\n",
        "        f4_pool = self.avgpool(f4).view(f4.size(0), -1)\n",
        "\n",
        "        x_recon2, z2 = self.sae2(f2_pool)\n",
        "        x_recon3, z3 = self.sae3(f3_pool)\n",
        "        x_recon4, z4 = self.sae4(f4_pool)\n",
        "\n",
        "        z_concat = torch.cat([z2, z3, z4], dim=1)\n",
        "\n",
        "        class_logits = self.classifier(z_concat)\n",
        "\n",
        "        return (class_logits,\n",
        "                (x_recon2, z2),\n",
        "                (x_recon3, z3),\n",
        "                (x_recon4, z4),\n",
        "                (f2_pool, f3_pool, f4_pool))"
      ],
      "metadata": {
        "id": "U-dyfxWWA3SC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Losses"
      ],
      "metadata": {
        "id": "41ugZ06WBPER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def irm_penalty(logits, labels):\n",
        "\n",
        "    scale = torch.tensor(1.0, requires_grad=True, device=logits.device)\n",
        "    loss_erm = F.cross_entropy(scale * logits, labels)\n",
        "\n",
        "    grad = torch.autograd.grad(loss_erm, [scale], create_graph=True)[0]\n",
        "\n",
        "    penalty = torch.sum(grad**2)\n",
        "\n",
        "    logit_mean = torch.mean(logits, dim=0)\n",
        "    var = torch.sum((logits - logit_mean.unsqueeze(0))**2)\n",
        "\n",
        "    return loss_erm, penalty, var"
      ],
      "metadata": {
        "id": "1L9aXvYeBRLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sae_loss(recons, pools, zs, lambda_sparse=[1.0, 1.0, 1.0], lambda_reconstruction=[1.0, 1.0, 1.0]):\n",
        "\n",
        "    x2_recon, x3_recon, x4_recon = recons\n",
        "    f2p, f3p, f4p = pools\n",
        "    z2, z3, z4 = zs\n",
        "\n",
        "    rec_loss2 = F.mse_loss(x2_recon, f2p)\n",
        "    rec_loss3 = F.mse_loss(x3_recon, f3p)\n",
        "    rec_loss4 = F.mse_loss(x4_recon, f4p)\n",
        "\n",
        "    lambda_r1, lambda_r2, lambda_r3 = lambda_reconstruction\n",
        "    recon_loss_total = (lambda_r1 * rec_loss2 + lambda_r2 * rec_loss3 + lambda_r3 * rec_loss4)\n",
        "\n",
        "    l1_z2 = torch.mean(torch.abs(z2))\n",
        "    l1_z3 = torch.mean(torch.abs(z3))\n",
        "    l1_z4 = torch.mean(torch.abs(z4))\n",
        "    lambda_s1, lambda_s2, lambda_s3 = lambda_sparse\n",
        "    l1_sparsity_total = (lambda_s1 * l1_z2 + lambda_s2 * l1_z3 + lambda_s3 * l1_z4)\n",
        "\n",
        "    return recon_loss_total, l1_sparsity_total\n"
      ],
      "metadata": {
        "id": "5o_c5NnbBbB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trian and Evaluate Functions"
      ],
      "metadata": {
        "id": "HSt6tjAxBkrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "9asqo-VoExhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_warmup(model, loader_source_domain1, loader_source_domain2, loader_test,\n",
        "                 num_warmup_epochs=5,\n",
        "                 lr=1e-4,\n",
        "                 device='cuda'):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.feature_extractor.parameters(), 'lr': lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': lr},\n",
        "    ], lr=lr)\n",
        "\n",
        "    for epoch in range(num_warmup_epochs):\n",
        "\n",
        "        domain1_iter = iter(loader_source_domain1)\n",
        "        domain2_iter = iter(loader_source_domain2)\n",
        "        steps_per_epoch = max(len(domain1_iter), len(domain2_iter))\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_samples = 0\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            try:\n",
        "                x_s1, y_s1 = next(domain1_iter)\n",
        "            except StopIteration:\n",
        "                domain1_iter = iter(loader_source_domain1)\n",
        "                x_s1, y_s1 = next(domain1_iter)\n",
        "\n",
        "            try:\n",
        "                x_s2, y_s2 = next(domain2_iter)\n",
        "            except StopIteration:\n",
        "                domain2_iter = iter(loader_source_domain2)\n",
        "                x_s2, y_s2 = next(domain2_iter)\n",
        "\n",
        "\n",
        "            x_source = torch.cat([x_s1, x_s2], dim=0)\n",
        "            y_source = torch.cat([y_s1, y_s2], dim=0)\n",
        "\n",
        "            indices = torch.randperm(x_source.size(0))\n",
        "            x_source = x_source[indices]\n",
        "            y_source = y_source[indices]\n",
        "\n",
        "            x_source, y_source = x_source.to(device), y_source.to(device)\n",
        "\n",
        "            class_logits, _, _, _, _ = model(x_source, grl_enabled=False)\n",
        "            loss_cls = F.cross_entropy(class_logits, y_source)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_cls.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            bs = x_source.size(0)\n",
        "            total_loss += loss_cls.item() * bs\n",
        "            total_samples += bs\n",
        "\n",
        "        epoch_loss = total_loss / total_samples\n",
        "        print(f\"[Warmup] Epoch [{epoch+1}/{num_warmup_epochs}] Loss: {epoch_loss:.4f}\")\n",
        "        test_acc = evaluate(model, loader_test, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_warmup_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n"
      ],
      "metadata": {
        "id": "E19t-5ocBkdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main(model,\n",
        "               loader_domain1,\n",
        "               loader_domain2,\n",
        "               test_loader,\n",
        "               num_epochs=20,\n",
        "               lr=1e-4,\n",
        "               lambda_irm=1.0,\n",
        "               lambda_sae_rec=1.0,\n",
        "               lambda_sae_sparse=1e-4,\n",
        "               device='cuda'):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        d1_iter = iter(loader_domain1)\n",
        "        d2_iter   = iter(loader_domain2)\n",
        "\n",
        "        steps_per_epoch = max(len(d1_iter), len(d2_iter))\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s1, y_s1 = next(d1_iter)\n",
        "            except StopIteration:\n",
        "                d1_iter = iter(loader_domain1)\n",
        "                x_s1, y_s1 = next(d1_iter)\n",
        "\n",
        "            try:\n",
        "                x_s2, y_s2 = next(d2_iter)\n",
        "            except StopIteration:\n",
        "                d2_iter = iter(loader_domain2)\n",
        "                x_s2, y_s2 = next(d2_iter)\n",
        "\n",
        "            x_s1, y_s1 = x_s1.to(device), y_s1.to(device)\n",
        "            x_s2, y_s2 = x_s2.to(device), y_s2.to(device)\n",
        "\n",
        "\n",
        "            logits_s1, _, _, _, _ = model(x_s1, grl_enabled=False)\n",
        "            logits_s2, _, _, _, _ = model(x_s2, grl_enabled=False)\n",
        "\n",
        "            loss_erm_s1, penalty_s1 = irm_penalty(logits_s1, y_s1)\n",
        "            loss_erm_s2, penalty_s2 = irm_penalty(logits_s2,   y_s2)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s1 + loss_erm_s2)\n",
        "            irm_pen  = 0.5 * (penalty_s1 + penalty_s2)\n",
        "            loss_irm = irm_loss + lambda_irm * irm_pen\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, _, _, _, f4p_s1 = model(x_s1, grl_enabled=False)\n",
        "                _, _, _, _, f4p_s2 = model(x_s2, grl_enabled=False)\n",
        "\n",
        "\n",
        "            x_recon_s1, z_s1 = model.sae(f4p_s1)\n",
        "            x_recon_s2, z_s2 = model.sae(f4p_s2)\n",
        "\n",
        "            recon_loss_s1 = F.mse_loss(x_recon_s1, f4p_s1)\n",
        "            recon_loss_s2 = F.mse_loss(x_recon_s2, f4p_s2)\n",
        "            recon_loss   = 0.5 * (recon_loss_s1 + recon_loss_s2)\n",
        "\n",
        "            l1_sparsity_s1 = torch.mean(torch.abs(z_s1))\n",
        "            l1_sparsity_s2 = torch.mean(torch.abs(z_s2))\n",
        "            l1_sparsity   = 0.5 * (l1_sparsity_s1 + l1_sparsity_s2)\n",
        "\n",
        "            sae_loss = lambda_sae_rec * recon_loss + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 10 == 0:\n",
        "                print(f\"[Main] Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "PjZgHALrBhiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baseline_model_office(model,\n",
        "                         loader_source,\n",
        "                         target_loader,\n",
        "                         num_epochs=20,\n",
        "                         lr=1e-4,\n",
        "                         lambda_irm=1.0,\n",
        "                         device='cuda'):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            logits_s, _ = model(x_s)\n",
        "            loss_erm_s, penalty_s = irm_penalty(logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s)\n",
        "            irm_pen  = 0.5 * (penalty_s)\n",
        "            loss_irm = irm_loss + lambda_irm * irm_pen\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_irm.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 10 == 0:\n",
        "                print(f\"[Baseline IRM] Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                      f\"Step [{step+1}/{steps_per_epoch}], IRM Loss: {loss_irm.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate_baseline(model, target_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YW4uDN9AEZB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main_irm_multi_sae_office(model,\n",
        "                              loader_source,\n",
        "                              test_loader,\n",
        "                              num_epochs=20,\n",
        "                              lr=1e-4,\n",
        "                              lambda_irm=1.0,\n",
        "                              lambda_sae_rec=1.0,\n",
        "                              lambda_sae_sparse=1e-4,\n",
        "                              lambda_sparse=[1.0, 1.0, 1.0],\n",
        "                              lambda_reconstruction=[1.0, 1.0, 1.0],\n",
        "                              lambda_irm_pair=[1.0, 1.0, 1.0],\n",
        "                              device='cuda',\n",
        "                              verbose=False):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    def sae_forward_splits(f2p, f3p, f4p):\n",
        "        x_recon2, z2 = model.sae2(f2p)\n",
        "        x_recon3, z3 = model.sae3(f3p)\n",
        "        x_recon4, z4 = model.sae4(f4p)\n",
        "        return x_recon2, z2, x_recon3, z3, x_recon4, z4\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            class_logits_s, _, _, _, _ = model(x_s)\n",
        "\n",
        "            loss_erm_s, penalty_s, var_s = irm_penalty(class_logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s)\n",
        "            irm_pen  = 0.5 * (penalty_s)\n",
        "\n",
        "\n",
        "            w1, w2, w3 = lambda_irm_pair\n",
        "            loss_irm = w1 * (irm_loss) + w2 * (lambda_irm * irm_pen) + w3 * var_s\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, (x_recon2_s, z2_s), (x_recon3_s, z3_s), (x_recon4_s, z4_s), (f2p_s, f3p_s, f4p_s) = model(x_s)\n",
        "\n",
        "            x_recon2_s, z2_s, x_recon3_s, z3_s, x_recon4_s, z4_s = sae_forward_splits(f2p_s, f3p_s, f4p_s)\n",
        "\n",
        "            lambda_s1, lambda_s2, lambda_s3 = lambda_sparse\n",
        "            lambda_r1, lambda_r2, lambda_r3 = lambda_reconstruction\n",
        "\n",
        "            rec_loss2_s = F.mse_loss(x_recon2_s, f2p_s)\n",
        "            rec_loss2   = lambda_r1 * (rec_loss2_s)\n",
        "\n",
        "            rec_loss3_s = F.mse_loss(x_recon3_s, f3p_s)\n",
        "            rec_loss3   = lambda_r2 * (rec_loss3_s)\n",
        "\n",
        "            rec_loss4_s = F.mse_loss(x_recon4_s, f4p_s)\n",
        "            rec_loss4   = lambda_r3 * (rec_loss4_s)\n",
        "\n",
        "            rec_loss_total = (rec_loss2 + rec_loss3 + rec_loss4)\n",
        "\n",
        "            l1_2_s = torch.mean(torch.abs(z2_s))\n",
        "            l1_2   = lambda_s1 * (l1_2_s)\n",
        "\n",
        "            l1_3_s = torch.mean(torch.abs(z3_s))\n",
        "            l1_3   = lambda_s2 * (l1_3_s)\n",
        "\n",
        "            l1_4_s = torch.mean(torch.abs(z4_s))\n",
        "            l1_4   = lambda_s3 * (l1_4_s)\n",
        "\n",
        "            l1_sparsity = l1_2 + l1_3 + l1_4\n",
        "\n",
        "            sae_loss = lambda_sae_rec * rec_loss_total + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 40 == 0 and verbose:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9n1I3VJsEgb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_irm_sae_with_warmup_office(\n",
        "    batch_size=32,\n",
        "    num_warmup_epochs=5,\n",
        "    num_main_epochs=20,\n",
        "    lr=1e-4,\n",
        "    lambda_irm=1.0,\n",
        "    lambda_sae_rec=1.0,\n",
        "    lambda_sae_sparse=1e-4,\n",
        "    device='cuda',\n",
        "    loader=['A', 'W'],\n",
        "    model=None,\n",
        "    verbose=False,\n",
        "    lambda_sparse=[1.0, 1.0, 1.0],\n",
        "    lambda_reconstruction=[1.0, 1.0, 1.0],\n",
        "    lambda_irm_pair=[1.0, 1.0, 0.0],\n",
        "):\n",
        "\n",
        "    loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(batch_size)\n",
        "\n",
        "    source, target = loader if loader is not None else ['A', 'W']\n",
        "\n",
        "    if source == 'A':\n",
        "        loader_source = loader_amazon\n",
        "    elif source == 'W':\n",
        "        loader_source = loader_webcam\n",
        "    elif source == 'D':\n",
        "        loader_source = loader_dslr\n",
        "\n",
        "    if target == 'A':\n",
        "        loader_target = loader_amazon\n",
        "    elif target == 'W':\n",
        "        loader_target = loader_webcam\n",
        "    elif target == 'D':\n",
        "        loader_target = loader_dslr\n",
        "\n",
        "\n",
        "    if model is None:\n",
        "        model = UnifiedModelMultiBlockSAE(512, 1024, 2048, 31)\n",
        "\n",
        "    print(\"===== Main Phase (IRM + SAE) =====\")\n",
        "\n",
        "    model = train_main_irm_multi_sae_office(model,\n",
        "                                            loader_source=loader_source,\n",
        "                                            test_loader=loader_target,\n",
        "                                            num_epochs=num_main_epochs,\n",
        "                                            lr=lr,\n",
        "                                            lambda_irm=lambda_irm,\n",
        "                                            lambda_sae_rec=lambda_sae_rec,\n",
        "                                            lambda_sae_sparse=lambda_sae_sparse,\n",
        "                                            device=device,\n",
        "                                            verbose=verbose,\n",
        "                                            lambda_sparse=lambda_sparse,\n",
        "                                            lambda_reconstruction=lambda_reconstruction,\n",
        "                                            lambda_irm_pair=lambda_irm_pair\n",
        "                                            )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fK8JO5c-Epys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "k9Y3ne2WE0z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    model.train()\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "I1JnoZwcEqPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _, _, _, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "9ZVa9RfWEs12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "5Efg0fiMHjya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_baseline = VGGFeatureExtractor(pretrained=True)\n",
        "baseline_model = BaselineModel(feature_extractor=feature_extractor_baseline, num_classes=31)"
      ],
      "metadata": {
        "id": "Qp2dr4NFIwu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97e8a5f-f880-4aa8-ef0b-ab8979db5067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 223MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(32)"
      ],
      "metadata": {
        "id": "_JeZUuvRJsqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8628d085-2195-4f1d-a9cc-7accca15662c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG-19 Backbone"
      ],
      "metadata": {
        "id": "_Ox3-4bMsJx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"W\"], [\"A\", \"D\"], [\"W\", \"A\"], [\"W\", \"D\"], [\"D\", \"W\"], [\"D\", \"A\"]]"
      ],
      "metadata": {
        "id": "t_SlveeHsNil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backbone with\n",
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=2e-5,\n",
        "            lambda_irm=4.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            loader=combination,\n",
        "            verbose=False\n",
        "        )\n",
        "    print(\"--------------------------------------------\")"
      ],
      "metadata": {
        "id": "cB70ubs5sQFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909be268-7302-4f37-8ce7-6a589a09ac7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Combination: ['A', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:02<00:00, 220MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 15.86% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 18.07% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 25.70% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 21.69% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 35.54% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 31.73% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 30.52% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 22.69% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 29.72% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 33.94% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 38.15% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 33.94% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 36.55% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 42.97% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 42.77% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 44.38% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 40.16% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 42.17% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 41.77% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 46.59% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 46.39% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 38.15% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 40.36% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 47.99% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 45.78% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 47.39% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 50.40% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 47.39% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 50.20% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 47.99% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 12.45% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 16.98% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 21.51% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 28.30% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 31.57% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 26.29% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 23.90% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 27.17% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 40.00% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 31.19% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 38.49% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 35.35% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 35.72% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 37.61% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 39.37% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 40.00% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 36.98% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 35.85% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 37.23% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 44.78% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 41.13% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 38.87% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 36.60% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 40.00% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 37.23% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 36.35% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 33.71% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 37.11% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 33.08% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 30.69% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 5.57% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 5.29% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 8.84% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 7.53% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 6.18% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 10.22% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 13.21% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 9.02% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 14.34% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 18.21% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 16.79% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 12.78% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 21.69% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 24.67% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 22.36% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 28.33% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 23.15% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 24.42% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 27.62% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 25.70% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 27.55% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 25.42% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 25.99% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 27.62% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 25.06% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 25.99% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 27.26% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 27.72% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 26.34% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 26.59% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 5.16% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 4.65% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 9.18% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 10.82% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 21.13% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 17.86% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 12.33% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 24.40% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 22.64% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 32.33% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 29.18% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 33.33% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 35.09% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 36.10% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 39.25% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 56.23% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 32.20% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 29.31% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 36.48% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 38.49% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 43.90% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 59.12% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 61.76% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 68.05% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 74.09% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 77.48% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 77.74% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 83.14% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 82.64% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 82.26% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 11.24% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 11.24% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 5.62% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 12.25% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 13.05% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 15.46% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 6.22% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 16.47% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 32.13% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 37.15% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 47.79% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 55.82% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 54.62% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 65.86% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 63.86% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 77.91% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 82.53% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 83.94% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 84.14% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 85.54% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 86.14% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 84.74% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 86.14% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 85.74% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 86.75% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 84.94% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 86.35% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 85.54% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 85.54% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 85.34% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 4.40% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 9.80% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 8.63% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 8.09% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 6.46% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 6.85% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 6.92% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 10.58% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 20.80% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 21.30% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 15.37% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 27.01% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 21.97% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 23.18% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 25.95% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 24.39% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 30.24% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 30.00% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 30.28% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 30.46% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 29.75% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 29.46% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 29.29% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 28.93% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 29.32% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 29.04% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 29.32% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 29.29% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 29.36% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 29.29% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG-16 Backbone"
      ],
      "metadata": {
        "id": "5USmgOTtD7Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_baseline = VGGFeatureExtractor(pretrained=True)\n",
        "baseline_model = BaselineModel(feature_extractor=feature_extractor_baseline, num_classes=31)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6D5G_WZEMoO",
        "outputId": "4b514f7e-0f56-454a-dffd-874a679a66c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"W\"], [\"A\", \"D\"], [\"W\", \"A\"], [\"W\", \"D\"], [\"D\", \"W\"], [\"D\", \"A\"]]"
      ],
      "metadata": {
        "id": "NND1i4CkHaMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backbone with\n",
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=2e-5,\n",
        "            lambda_irm=4.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            loader=combination,\n",
        "            verbose=False\n",
        "        )\n",
        "    print(\"--------------------------------------------\")"
      ],
      "metadata": {
        "id": "OnElMzQ-Ilif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1ec717-e227-4535-b2ca-56897664d9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 31.33% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 29.52% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 44.38% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 44.38% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 43.17% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 49.40% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 41.57% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 56.02% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 53.41% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 56.22% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 60.24% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 58.03% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 59.04% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 63.45% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 62.65% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 65.06% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 56.43% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 51.20% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 60.04% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 62.85% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 64.46% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 64.26% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 62.45% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 63.86% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 63.86% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 63.05% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 62.25% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 61.85% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 62.85% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 62.65% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 16.98% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 33.33% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 31.32% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 37.74% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 33.46% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 43.14% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 35.35% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 40.88% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 47.42% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 36.98% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 44.91% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 46.54% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 43.14% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 45.79% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 51.57% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 50.82% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 54.21% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 50.31% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 38.62% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 53.96% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 53.58% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 51.70% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 49.94% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 48.55% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 45.28% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 47.42% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 43.90% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 42.89% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 47.67% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 44.40% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 8.84% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 3.87% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 5.72% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 5.79% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 7.63% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 7.63% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 12.14% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 16.22% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 17.11% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 15.09% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 15.44% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 19.03% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 29.64% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 24.32% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 32.09% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 36.92% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 39.69% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 41.64% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 42.88% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 41.64% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 43.56% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 42.85% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 43.98% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 44.37% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 44.37% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 43.91% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 44.20% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 43.84% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 44.02% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 43.95% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 18.62% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 5.03% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 9.69% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 9.69% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 12.83% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 14.72% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 28.81% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 36.73% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 48.55% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 63.90% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 64.15% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 66.16% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 79.37% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 88.30% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 86.29% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 84.28% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 86.42% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 84.15% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 86.92% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 85.66% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 86.67% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 85.53% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 85.79% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 86.16% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 85.16% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 85.53% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 84.40% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 83.77% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 84.91% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 83.77% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 4.42% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 5.42% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 10.64% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 22.29% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 30.52% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 34.34% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 38.15% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 48.19% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 58.23% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 75.50% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 82.33% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 82.33% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 92.17% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 93.57% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 92.97% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 95.38% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 95.98% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 95.18% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 94.98% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 95.38% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 12.00% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 6.92% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 8.84% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 10.83% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 14.34% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 15.30% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 18.81% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 23.00% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 25.74% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 21.41% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 27.58% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 37.49% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 36.49% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 36.35% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 41.78% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 42.92% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 41.75% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 42.60% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 40.50% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 41.75% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 41.89% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 41.50% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 41.64% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 41.39% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 41.36% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 41.14% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 41.04% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 40.72% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 40.68% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 41.14% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"D\"], [\"W\", \"A\"]]"
      ],
      "metadata": {
        "id": "KxlEh9eFFcEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=2e-5,\n",
        "            lambda_irm=4.0,\n",
        "            lambda_sae_rec=3.0,\n",
        "            lambda_sae_sparse=3e-4,\n",
        "            device='cuda',\n",
        "            loader=combination,\n",
        "            verbose=False\n",
        "        )\n",
        "    print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tukvJIhjHcWU",
        "outputId": "7b688354-f046-41af-ded5-4a2ce3a96ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 19.37% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 22.14% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 34.47% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 40.38% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 48.68% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 49.18% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 52.58% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 49.43% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 56.60% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 52.45% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 58.62% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 59.50% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 59.37% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 57.23% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 58.74% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 51.32% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 56.23% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 52.45% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 55.60% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 53.46% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 53.08% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 48.55% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 51.95% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 51.19% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 52.33% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 50.82% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 50.57% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 50.69% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 50.31% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 50.82% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 10.61% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 5.47% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 7.35% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 7.42% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 11.18% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 13.31% **\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7a4198ea53a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"------------Combination: {combination}--------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnum_warmup_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-a7ea9a602487>\u001b[0m in \u001b[0;36mtrain_model_irm_sae_with_warmup_office\u001b[0;34m(batch_size, num_warmup_epochs, num_main_epochs, lr, lambda_irm, lambda_sae_rec, lambda_sae_sparse, device, loader, model, verbose, lambda_sparse, lambda_reconstruction, lambda_irm_pair)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Main Phase (IRM + SAE) =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     model = train_main_irm_multi_sae_office(model,\n\u001b[0m\u001b[1;32m     43\u001b[0m                                             \u001b[0mloader_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                             \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ddc8556160ea>\u001b[0m in \u001b[0;36mtrain_main_irm_multi_sae_office\u001b[0;34m(model, loader_source, test_loader, num_epochs, lr, lambda_irm, lambda_sae_rec, lambda_sae_sparse, lambda_sparse, lambda_reconstruction, lambda_irm_pair, device, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m                       f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-87e9eb756b7a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG19 Model"
      ],
      "metadata": {
        "id": "TiD4cZDzrvsr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bg0I0EU4rxhN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}