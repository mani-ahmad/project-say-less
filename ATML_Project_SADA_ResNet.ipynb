{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "spAb68AuAgn6",
        "wp0Ewd14AnBj",
        "41ugZ06WBPER",
        "k9Y3ne2WE0z1",
        "ymRBA9OTImee"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Z75mnFTp_ztC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "90a36d8b-7ae7-4027-819e-e90abe054ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIbI4UQ3_rn-"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Datasets\n",
        "from datasets import load_dataset\n",
        "import kagglehub\n",
        "\n",
        "# Extra\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Office-31"
      ],
      "metadata": {
        "id": "spAb68AuAgn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Office31(domain, transform):\n",
        "    path = kagglehub.dataset_download(\"xixuhu/office31\")\n",
        "    path = os.path.join(os.path.join(path, \"Office-31\"), domain)\n",
        "    return datasets.ImageFolder(root=path, transform=transform)\n",
        "\n",
        "def get_office_data_loaders(batch_size):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    amazon_data = Office31(\"amazon\", transform)\n",
        "    dslr_data = Office31(\"dslr\", transform)\n",
        "    webcam_data = Office31(\"webcam\", transform)\n",
        "\n",
        "    loader_amazon = DataLoader(amazon_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_dslr = DataLoader(dslr_data, batch_size=batch_size, shuffle=True)\n",
        "    loader_webcam = DataLoader(webcam_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader_amazon, loader_dslr, loader_webcam"
      ],
      "metadata": {
        "id": "NnwP93vyAIgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_amazon, loader_dslr, loader_webcam = get_office_data_loaders(batch_size=32)"
      ],
      "metadata": {
        "id": "R8lCJWalAiyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429003a7-2f3e-4a7e-d454-460469fc770d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pacs"
      ],
      "metadata": {
        "id": "QXWb4KN2AlBd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KbFM2fmAmor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Py4n_wFMBSYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Cards"
      ],
      "metadata": {
        "id": "wp0Ewd14AnBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        base_model = torchvision.models.resnet50(pretrained=pretrained)\n",
        "        self.conv1 = base_model.conv1\n",
        "        self.bn1 = base_model.bn1\n",
        "        self.relu = base_model.relu\n",
        "        self.maxpool = base_model.maxpool\n",
        "        self.layer1 = base_model.layer1\n",
        "        self.layer2 = base_model.layer2\n",
        "        self.layer3 = base_model.layer3\n",
        "        self.layer4 = base_model.layer4\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        f_block1 = self.layer1(x)\n",
        "        f_block2 = self.layer2(f_block1)\n",
        "        f_block3 = self.layer3(f_block2)\n",
        "        f_block4 = self.layer4(f_block3)\n",
        "\n",
        "        return f_block2, f_block3, f_block4"
      ],
      "metadata": {
        "id": "Hr4oJ4dfApKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, z"
      ],
      "metadata": {
        "id": "HLNY65W8AskS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierHead(nn.Module):\n",
        "    def __init__(self, input_dim=2048, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "HA2XtH6zAuX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, feature_extractor, num_classes=7):\n",
        "\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.classifier = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, f4 = self.feature_extractor(x)\n",
        "        f4_pool = self.avgpool(f4).view(f4.size(0), -1)\n",
        "\n",
        "        logits = self.classifier(f4_pool)\n",
        "        return logits, f4_pool\n"
      ],
      "metadata": {
        "id": "Xjm7SG84A22J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnifiedModelMultiBlockSAE(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sae_dim_block2=128,\n",
        "                 sae_dim_block3=256,\n",
        "                 sae_dim_block4=256,\n",
        "                 num_classes=7):\n",
        "\n",
        "        super().__init__()\n",
        "        self.feature_extractor = ResNetFeatureExtractor(pretrained=True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.sae2 = SparseAutoencoder(input_dim=512, hidden_dim=sae_dim_block2)\n",
        "        self.sae3 = SparseAutoencoder(input_dim=1024, hidden_dim=sae_dim_block3)\n",
        "        self.sae4 = SparseAutoencoder(input_dim=2048, hidden_dim=sae_dim_block4)\n",
        "\n",
        "        total_hidden = sae_dim_block2 + sae_dim_block3 + sae_dim_block4\n",
        "        self.classifier = nn.Linear(total_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        f2, f3, f4 = self.feature_extractor(x)\n",
        "\n",
        "        f2_pool = self.avgpool(f2).view(f2.size(0), -1)\n",
        "        f3_pool = self.avgpool(f3).view(f3.size(0), -1)\n",
        "        f4_pool = self.avgpool(f4).view(f4.size(0), -1)\n",
        "\n",
        "        x_recon2, z2 = self.sae2(f2_pool)\n",
        "        x_recon3, z3 = self.sae3(f3_pool)\n",
        "        x_recon4, z4 = self.sae4(f4_pool)\n",
        "\n",
        "        z_concat = torch.cat([z2, z3, z4], dim=1)\n",
        "\n",
        "        class_logits = self.classifier(z_concat)\n",
        "\n",
        "        return (class_logits,\n",
        "                (x_recon2, z2),\n",
        "                (x_recon3, z3),\n",
        "                (x_recon4, z4),\n",
        "                (f2_pool, f3_pool, f4_pool))"
      ],
      "metadata": {
        "id": "U-dyfxWWA3SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Losses"
      ],
      "metadata": {
        "id": "41ugZ06WBPER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def irm_penalty(logits, labels):\n",
        "\n",
        "    scale = torch.tensor(1.0, requires_grad=True, device=logits.device)\n",
        "    loss_erm = F.cross_entropy(scale * logits, labels)\n",
        "\n",
        "    grad = torch.autograd.grad(loss_erm, [scale], create_graph=True)[0]\n",
        "\n",
        "    penalty = torch.sum(grad**2)\n",
        "\n",
        "    return loss_erm, penalty"
      ],
      "metadata": {
        "id": "1L9aXvYeBRLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sae_loss(recons, pools, zs):\n",
        "\n",
        "    x2_recon, x3_recon, x4_recon = recons\n",
        "    f2p, f3p, f4p = pools\n",
        "    z2, z3, z4 = zs\n",
        "\n",
        "    rec_loss2 = F.mse_loss(x2_recon, f2p)\n",
        "    rec_loss3 = F.mse_loss(x3_recon, f3p)\n",
        "    rec_loss4 = F.mse_loss(x4_recon, f4p)\n",
        "    recon_loss_total = (rec_loss2 + rec_loss3 + rec_loss4)\n",
        "\n",
        "    l1_z2 = torch.mean(torch.abs(z2))\n",
        "    l1_z3 = torch.mean(torch.abs(z3))\n",
        "    l1_z4 = torch.mean(torch.abs(z4))\n",
        "    l1_sparsity_total = (l1_z2 + l1_z3 + l1_z4)\n",
        "\n",
        "    return recon_loss_total, l1_sparsity_total\n"
      ],
      "metadata": {
        "id": "5o_c5NnbBbB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trian and Evaluate Functions"
      ],
      "metadata": {
        "id": "HSt6tjAxBkrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "9asqo-VoExhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_warmup(model, loader_source_domain1, loader_source_domain2, loader_test,\n",
        "                 num_warmup_epochs=5,\n",
        "                 lr=1e-4,\n",
        "                 device='cuda'):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.feature_extractor.parameters(), 'lr': lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': lr},\n",
        "    ], lr=lr)\n",
        "\n",
        "    for epoch in range(num_warmup_epochs):\n",
        "\n",
        "        domain1_iter = iter(loader_source_domain1)\n",
        "        domain2_iter = iter(loader_source_domain2)\n",
        "        steps_per_epoch = max(len(domain1_iter), len(domain2_iter))\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_samples = 0\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            try:\n",
        "                x_s1, y_s1 = next(domain1_iter)\n",
        "            except StopIteration:\n",
        "                domain1_iter = iter(loader_source_domain1)\n",
        "                x_s1, y_s1 = next(domain1_iter)\n",
        "\n",
        "            try:\n",
        "                x_s2, y_s2 = next(domain2_iter)\n",
        "            except StopIteration:\n",
        "                domain2_iter = iter(loader_source_domain2)\n",
        "                x_s2, y_s2 = next(domain2_iter)\n",
        "\n",
        "\n",
        "            x_source = torch.cat([x_s1, x_s2], dim=0)\n",
        "            y_source = torch.cat([y_s1, y_s2], dim=0)\n",
        "\n",
        "            indices = torch.randperm(x_source.size(0))\n",
        "            x_source = x_source[indices]\n",
        "            y_source = y_source[indices]\n",
        "\n",
        "            x_source, y_source = x_source.to(device), y_source.to(device)\n",
        "\n",
        "            class_logits, _, _, _, _ = model(x_source, grl_enabled=False)\n",
        "            loss_cls = F.cross_entropy(class_logits, y_source)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_cls.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            bs = x_source.size(0)\n",
        "            total_loss += loss_cls.item() * bs\n",
        "            total_samples += bs\n",
        "\n",
        "        epoch_loss = total_loss / total_samples\n",
        "        print(f\"[Warmup] Epoch [{epoch+1}/{num_warmup_epochs}] Loss: {epoch_loss:.4f}\")\n",
        "        test_acc = evaluate(model, loader_test, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_warmup_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n"
      ],
      "metadata": {
        "id": "E19t-5ocBkdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main(model,\n",
        "               loader_domain1,\n",
        "               loader_domain2,\n",
        "               test_loader,\n",
        "               num_epochs=20,\n",
        "               lr=1e-4,\n",
        "               lambda_irm=1.0,\n",
        "               lambda_sae_rec=1.0,\n",
        "               lambda_sae_sparse=1e-4,\n",
        "               device='cuda'):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        d1_iter = iter(loader_domain1)\n",
        "        d2_iter   = iter(loader_domain2)\n",
        "\n",
        "        steps_per_epoch = max(len(d1_iter), len(d2_iter))\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s1, y_s1 = next(d1_iter)\n",
        "            except StopIteration:\n",
        "                d1_iter = iter(loader_domain1)\n",
        "                x_s1, y_s1 = next(d1_iter)\n",
        "\n",
        "            try:\n",
        "                x_s2, y_s2 = next(d2_iter)\n",
        "            except StopIteration:\n",
        "                d2_iter = iter(loader_domain2)\n",
        "                x_s2, y_s2 = next(d2_iter)\n",
        "\n",
        "            x_s1, y_s1 = x_s1.to(device), y_s1.to(device)\n",
        "            x_s2, y_s2 = x_s2.to(device), y_s2.to(device)\n",
        "\n",
        "\n",
        "            logits_s1, _, _, _, _ = model(x_s1, grl_enabled=False)\n",
        "            logits_s2, _, _, _, _ = model(x_s2, grl_enabled=False)\n",
        "\n",
        "            loss_erm_s1, penalty_s1 = irm_penalty(logits_s1, y_s1)\n",
        "            loss_erm_s2, penalty_s2 = irm_penalty(logits_s2,   y_s2)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s1 + loss_erm_s2)\n",
        "            irm_pen  = 0.5 * (penalty_s1 + penalty_s2)\n",
        "            loss_irm = irm_loss + lambda_irm * irm_pen\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, _, _, _, f4p_s1 = model(x_s1, grl_enabled=False)\n",
        "                _, _, _, _, f4p_s2 = model(x_s2, grl_enabled=False)\n",
        "\n",
        "\n",
        "            x_recon_s1, z_s1 = model.sae(f4p_s1)\n",
        "            x_recon_s2, z_s2 = model.sae(f4p_s2)\n",
        "\n",
        "            recon_loss_s1 = F.mse_loss(x_recon_s1, f4p_s1)\n",
        "            recon_loss_s2 = F.mse_loss(x_recon_s2, f4p_s2)\n",
        "            recon_loss   = 0.5 * (recon_loss_s1 + recon_loss_s2)\n",
        "\n",
        "            l1_sparsity_s1 = torch.mean(torch.abs(z_s1))\n",
        "            l1_sparsity_s2 = torch.mean(torch.abs(z_s2))\n",
        "            l1_sparsity   = 0.5 * (l1_sparsity_s1 + l1_sparsity_s2)\n",
        "\n",
        "            sae_loss = lambda_sae_rec * recon_loss + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 10 == 0:\n",
        "                print(f\"[Main] Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "PjZgHALrBhiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baseline_model_office(model,\n",
        "                         loader_source,\n",
        "                         target_loader,\n",
        "                         num_epochs=20,\n",
        "                         lr=1e-4,\n",
        "                         lambda_irm=1.0,\n",
        "                         device='cuda'):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            logits_s, _ = model(x_s)\n",
        "            loss_erm_s, penalty_s = irm_penalty(logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s)\n",
        "            irm_pen  = 0.5 * (penalty_s)\n",
        "            loss_irm = irm_loss + lambda_irm * irm_pen\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_irm.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 10 == 0:\n",
        "                print(f\"[Baseline IRM] Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                      f\"Step [{step+1}/{steps_per_epoch}], IRM Loss: {loss_irm.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate_baseline(model, target_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YW4uDN9AEZB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main_irm_multi_sae_office(model,\n",
        "                              loader_source,\n",
        "                              test_loader,\n",
        "                              num_epochs=20,\n",
        "                              lr=1e-4,\n",
        "                              lambda_irm=1.0,\n",
        "                              lambda_sae_rec=1.0,\n",
        "                              lambda_sae_sparse=1e-4,\n",
        "                              device='cuda',\n",
        "                              verbose=False):\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    def sae_forward_splits(f2p, f3p, f4p):\n",
        "        x_recon2, z2 = model.sae2(f2p)\n",
        "        x_recon3, z3 = model.sae3(f3p)\n",
        "        x_recon4, z4 = model.sae4(f4p)\n",
        "        return x_recon2, z2, x_recon3, z3, x_recon4, z4\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        source_iter = iter(loader_source)\n",
        "        steps_per_epoch = len(source_iter)\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "\n",
        "            try:\n",
        "                x_s, y_s = next(source_iter)\n",
        "            except StopIteration:\n",
        "                source_iter = iter(loader_source)\n",
        "                x_s, y_s = next(source_iter)\n",
        "\n",
        "            x_s, y_s = x_s.to(device), y_s.to(device)\n",
        "\n",
        "            class_logits_s, _, _, _, _ = model(x_s)\n",
        "\n",
        "            loss_erm_s, penalty_s = irm_penalty(class_logits_s, y_s)\n",
        "\n",
        "            irm_loss = 0.5 * (loss_erm_s)\n",
        "            irm_pen  = 0.5 * (penalty_s)\n",
        "\n",
        "            loss_irm = irm_loss + lambda_irm * irm_pen\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, (x_recon2_s, z2_s), (x_recon3_s, z3_s), (x_recon4_s, z4_s), (f2p_s, f3p_s, f4p_s) = model(x_s)\n",
        "\n",
        "            x_recon2_s, z2_s, x_recon3_s, z3_s, x_recon4_s, z4_s = sae_forward_splits(f2p_s, f3p_s, f4p_s)\n",
        "\n",
        "            rec_loss2_s = F.mse_loss(x_recon2_s, f2p_s)\n",
        "            rec_loss2   = 1 * (rec_loss2_s)\n",
        "\n",
        "            rec_loss3_s = F.mse_loss(x_recon3_s, f3p_s)\n",
        "            rec_loss3   = 1 * (rec_loss3_s)\n",
        "\n",
        "            rec_loss4_s = F.mse_loss(x_recon4_s, f4p_s)\n",
        "            rec_loss4   = 1 * (rec_loss4_s)\n",
        "\n",
        "            rec_loss_total = (rec_loss2 + rec_loss3 + rec_loss4)\n",
        "\n",
        "            l1_2_s = torch.mean(torch.abs(z2_s))\n",
        "            l1_2   = 1 * (l1_2_s)\n",
        "\n",
        "            l1_3_s = torch.mean(torch.abs(z3_s))\n",
        "            l1_3   = 1 * (l1_3_s)\n",
        "\n",
        "            l1_4_s = torch.mean(torch.abs(z4_s))\n",
        "            l1_4   = 1 * (l1_4_s)\n",
        "\n",
        "            l1_sparsity = l1_2 + l1_3 + l1_4\n",
        "\n",
        "            sae_loss = lambda_sae_rec * rec_loss_total + lambda_sae_sparse * l1_sparsity\n",
        "\n",
        "            loss = loss_irm + sae_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step+1) % 40 == 0 and verbose:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{steps_per_epoch}], \"\n",
        "                      f\"IRM Loss: {loss_irm.item():.4f}, SAE Loss: {sae_loss.item():.4f}\")\n",
        "\n",
        "        test_acc = evaluate(model, test_loader, device=device)\n",
        "        print(f\"** End of Epoch {epoch+1}/{num_epochs} | Test Accuracy: {test_acc:.2f}% **\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9n1I3VJsEgb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_irm_sae_with_warmup_office(\n",
        "    batch_size=32,\n",
        "    num_warmup_epochs=5,\n",
        "    num_main_epochs=20,\n",
        "    lr=1e-4,\n",
        "    lambda_irm=1.0,\n",
        "    lambda_sae_rec=1.0,\n",
        "    lambda_sae_sparse=1e-4,\n",
        "    device='cuda',\n",
        "    loader=['A', 'W'],\n",
        "    model=None,\n",
        "    verbose=False\n",
        "):\n",
        "\n",
        "    loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(batch_size)\n",
        "\n",
        "    source, target = loader if loader is not None else ['A', 'W']\n",
        "\n",
        "    if source == 'A':\n",
        "        loader_source = loader_amazon\n",
        "    elif source == 'W':\n",
        "        loader_source = loader_webcam\n",
        "    elif source == 'D':\n",
        "        loader_source = loader_dslr\n",
        "\n",
        "    if target == 'A':\n",
        "        loader_target = loader_amazon\n",
        "    elif target == 'W':\n",
        "        loader_target = loader_webcam\n",
        "    elif target == 'D':\n",
        "        loader_target = loader_dslr\n",
        "\n",
        "\n",
        "    if model is None:\n",
        "        model = UnifiedModelMultiBlockSAE(512, 1024, 2048, 31)\n",
        "\n",
        "    print(\"===== Main Phase (IRM + SAE) =====\")\n",
        "\n",
        "    model = train_main_irm_multi_sae_office(model,\n",
        "                                            loader_source=loader_source,\n",
        "                                            test_loader=loader_target,\n",
        "                                            num_epochs=num_main_epochs,\n",
        "                                            lr=lr,\n",
        "                                            lambda_irm=lambda_irm,\n",
        "                                            lambda_sae_rec=lambda_sae_rec,\n",
        "                                            lambda_sae_sparse=lambda_sae_sparse,\n",
        "                                            device=device,\n",
        "                                            verbose=verbose)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fK8JO5c-Epys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "k9Y3ne2WE0z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    model.train()\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "I1JnoZwcEqPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _, _, _, _ = model(x)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "9ZVa9RfWEs12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "5Efg0fiMHjya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_baseline = ResNetFeatureExtractor(pretrained=True)\n",
        "baseline_model = BaselineModel(feature_extractor=feature_extractor_baseline, num_classes=31)"
      ],
      "metadata": {
        "id": "Qp2dr4NFIwu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_amazon, loader_webcam, loader_dslr = get_office_data_loaders(32)"
      ],
      "metadata": {
        "id": "_JeZUuvRJsqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline models"
      ],
      "metadata": {
        "id": "ymRBA9OTImee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A -> W"
      ],
      "metadata": {
        "id": "CTzsP6NZKZxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_amazon,\n",
        "                         loader_webcam,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "srKMMW47IjrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A -> D"
      ],
      "metadata": {
        "id": "jPAtvyACKXkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_amazon,\n",
        "                         loader_dslr,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "T_ulkoK6JyBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### W -> A"
      ],
      "metadata": {
        "id": "zws7xJ33KVe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_webcam,\n",
        "                         loader_amazon,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "7DGytvoSJzKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### W -> D"
      ],
      "metadata": {
        "id": "0CbTmzFXKSN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_webcam,\n",
        "                         loader_dslr,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "-InAQbMXKAhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D -> W"
      ],
      "metadata": {
        "id": "JoF8qXCbKPd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_dslr,\n",
        "                         loader_webcam,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "bjWJ5JvEKDfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### D -> A"
      ],
      "metadata": {
        "id": "2XBdweCGKJyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = train_baseline_model_office(baseline_model,\n",
        "                         loader_dslr,\n",
        "                         loader_amazon,\n",
        "                         num_epochs=20,\n",
        "                         lr=3e-5,\n",
        "                         lambda_irm=4.0,\n",
        "                         device='cuda')"
      ],
      "metadata": {
        "id": "M65hwh2CKEzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ours"
      ],
      "metadata": {
        "id": "wyB1rTLlItrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"W\"], [\"A\", \"D\"], [\"W\", \"A\"], [\"W\", \"D\"], [\"D\", \"W\"], [\"D\", \"A\"]]"
      ],
      "metadata": {
        "id": "zTV3OWYxL0ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=2e-5,\n",
        "            lambda_irm=4.0,\n",
        "            lambda_sae_rec=2.0,\n",
        "            lambda_sae_sparse=2e-4,\n",
        "            device='cuda',\n",
        "            loader=combination,\n",
        "            verbose=False\n",
        "        )\n",
        "    print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "ht88PjKfIuxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b80e2ed-8e82-43b6-ed59-d7eb90716d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 8.43% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 12.85% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 27.51% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 40.96% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 50.40% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 56.83% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 60.04% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 66.06% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 70.08% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 69.08% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 74.70% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 74.90% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 73.29% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 76.31% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 69.08% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 69.88% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 70.68% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 72.49% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 72.69% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 72.09% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 72.69% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 72.29% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 73.09% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 72.29% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 72.49% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 71.69% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 72.49% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 72.49% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 72.09% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 72.09% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 6.04% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 26.42% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 39.87% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 36.23% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 51.19% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 54.21% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 57.86% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 48.05% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 43.40% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 46.54% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 44.78% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 54.47% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 54.09% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 51.07% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 59.12% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 62.01% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 56.73% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 59.87% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 60.75% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 59.50% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 61.51% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 61.51% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 61.26% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 61.76% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 60.25% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 61.01% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 61.01% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 60.75% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 61.01% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 61.13% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 3.66% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 3.55% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 3.55% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 3.59% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 5.57% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 9.12% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 7.99% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 15.02% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 14.48% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 27.51% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 43.77% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 48.99% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 43.95% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 52.57% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 54.31% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 53.99% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 53.60% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 53.99% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 53.67% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 53.50% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 53.43% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 53.46% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 53.53% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 53.50% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 53.46% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 53.46% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 53.57% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 53.43% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 53.46% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 53.46% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 8.30% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 2.39% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 6.29% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 18.74% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 9.56% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 12.83% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 31.57% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 23.77% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 24.65% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 34.47% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 49.31% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 71.32% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 83.27% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 89.43% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 92.45% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 93.71% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 94.09% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 94.97% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 94.97% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 94.97% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 94.84% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 95.09% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 95.09% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 95.35% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 95.35% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 95.22% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 95.35% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 95.22% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 95.09% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 95.09% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'W']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 6.83% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 4.42% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 9.84% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 14.46% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 15.86% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 22.29% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 23.69% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 47.59% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 71.29% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 78.31% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 87.75% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 93.78% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 94.18% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 95.78% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 95.58% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 95.58% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['D', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 4.26% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 5.86% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 8.52% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 16.79% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 23.18% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 25.84% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 33.51% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 23.46% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 35.07% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 38.13% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 46.36% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 48.85% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 51.33% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 51.01% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 51.40% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 51.15% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 51.22% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 51.05% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 51.19% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 51.19% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 51.15% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 51.08% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 51.26% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 51.08% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 51.08% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 51.01% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 50.98% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 50.98% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 50.98% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 51.05% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combinations = [[\"A\", \"D\"], [\"W\", \"A\"]]"
      ],
      "metadata": {
        "id": "EJqXNm9hOTyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for combination in combinations:\n",
        "    print(f\"------------Combination: {combination}--------------\")\n",
        "    trained_model_sae_office = train_model_irm_sae_with_warmup_office(\n",
        "            batch_size=32,\n",
        "            num_warmup_epochs=4,\n",
        "            num_main_epochs=30,\n",
        "            lr=2e-5,\n",
        "            lambda_irm=4.0,\n",
        "            lambda_sae_rec=3.0,\n",
        "            lambda_sae_sparse=3e-4,\n",
        "            device='cuda',\n",
        "            loader=combination,\n",
        "            verbose=False\n",
        "        )\n",
        "    print(\"--------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPYD3IiebrlK",
        "outputId": "46e54ccd-3e03-4c17-bea3-231972820503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Combination: ['A', 'D']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 4.65% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 14.84% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 38.74% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 44.40% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 49.94% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 61.76% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 61.01% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 63.02% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 63.52% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 54.47% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 63.90% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 64.40% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 63.65% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 64.03% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 65.79% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 65.03% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 66.42% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 63.40% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 62.26% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 62.01% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 58.74% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 71.70% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 67.67% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 66.79% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 66.79% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 65.91% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 66.79% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 65.79% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 65.53% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 65.53% **\n",
            "--------------------------------------------\n",
            "------------Combination: ['W', 'A']--------------\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "===== Main Phase (IRM + SAE) =====\n",
            "** End of Epoch 1/30 | Test Accuracy: 12.78% **\n",
            "** End of Epoch 2/30 | Test Accuracy: 4.40% **\n",
            "** End of Epoch 3/30 | Test Accuracy: 10.40% **\n",
            "** End of Epoch 4/30 | Test Accuracy: 3.19% **\n",
            "** End of Epoch 5/30 | Test Accuracy: 7.28% **\n",
            "** End of Epoch 6/30 | Test Accuracy: 5.79% **\n",
            "** End of Epoch 7/30 | Test Accuracy: 3.87% **\n",
            "** End of Epoch 8/30 | Test Accuracy: 4.12% **\n",
            "** End of Epoch 9/30 | Test Accuracy: 5.36% **\n",
            "** End of Epoch 10/30 | Test Accuracy: 3.59% **\n",
            "** End of Epoch 11/30 | Test Accuracy: 8.09% **\n",
            "** End of Epoch 12/30 | Test Accuracy: 10.76% **\n",
            "** End of Epoch 13/30 | Test Accuracy: 18.42% **\n",
            "** End of Epoch 14/30 | Test Accuracy: 12.89% **\n",
            "** End of Epoch 15/30 | Test Accuracy: 21.05% **\n",
            "** End of Epoch 16/30 | Test Accuracy: 28.61% **\n",
            "** End of Epoch 17/30 | Test Accuracy: 34.58% **\n",
            "** End of Epoch 18/30 | Test Accuracy: 39.58% **\n",
            "** End of Epoch 19/30 | Test Accuracy: 45.19% **\n",
            "** End of Epoch 20/30 | Test Accuracy: 43.98% **\n",
            "** End of Epoch 21/30 | Test Accuracy: 54.70% **\n",
            "** End of Epoch 22/30 | Test Accuracy: 52.15% **\n",
            "** End of Epoch 23/30 | Test Accuracy: 53.00% **\n",
            "** End of Epoch 24/30 | Test Accuracy: 53.21% **\n",
            "** End of Epoch 25/30 | Test Accuracy: 53.53% **\n",
            "** End of Epoch 26/30 | Test Accuracy: 53.67% **\n",
            "** End of Epoch 27/30 | Test Accuracy: 53.89% **\n",
            "** End of Epoch 28/30 | Test Accuracy: 54.06% **\n",
            "** End of Epoch 29/30 | Test Accuracy: 54.06% **\n",
            "** End of Epoch 30/30 | Test Accuracy: 54.17% **\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}